"""
ë¡±í¼ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë“ˆ (10-15ë¶„)
ìŒì„± ê¸°ë°˜ì˜ ë¡±í¼ ì½˜í…ì¸ ë¥¼ ìë§‰ê³¼ í•¨ê»˜ ìƒì„±í•©ë‹ˆë‹¤.
- HuggingFace AI ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„± (FLUX.1-schnell) + Pexels í´ë°±
- TextClipìœ¼ë¡œ ìë§‰ ìƒì„± (PNG ì—†ì´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
- sentence_timings ê¸°ë°˜ ìŒì„± ì‹±í¬ ìë§‰
"""

import json
import os
import random
import requests
import time
from PIL import Image, ImageDraw, ImageFont
import numpy as np

try:
    from moviepy import (
        ColorClip, AudioFileClip, CompositeVideoClip,
        TextClip, concatenate_videoclips, ImageClip
    )
except ImportError:
    from moviepy.editor import (
        ColorClip, AudioFileClip, CompositeVideoClip,
        TextClip, concatenate_videoclips, ImageClip
    )


class LongformVideoGenerator:
    # Pexels ê²€ìƒ‰ì— ì‚¬ìš©í•  ì˜ë¬¸ í‚¤ì›Œë“œ (ìˆœí™˜ ì‚¬ìš©)
    IMAGE_KEYWORDS = [
        "peaceful nature landscape",
        "city skyline sunset",
        "ocean waves calm",
        "mountain scenery fog",
        "forest path morning light",
        "starry night sky",
        "sunrise horizon clouds",
        "rain window mood",
        "autumn leaves path",
        "cloud sky dramatic",
        "lake reflection peaceful",
        "desert sand dunes",
    ]

    def __init__(self, config_path="config/config.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        # ë¹„ë””ì˜¤ ì„¤ì •
        cfg = self.config.get('video', {}).get('longform', {})
        res = cfg.get('resolution', '1920x1080').split('x')
        self.width = int(res[0])
        self.height = int(res[1])
        self.fps = cfg.get('fps', 30)
        self.bg_color = cfg.get('background_color', '#000000')
        self.text_color = cfg.get('text_color', '#ffffff')
        self.accent_color = cfg.get('accent_color', '#00d4ff')
        self.font_size = cfg.get('text_font_size', 48)

        # Pexels API í‚¤
        self.pexels_api_key = self.config.get('pexels_api_key', '')

        # HuggingFace API
        self.hf_token = self.config.get('huggingface_token', '')
        self.hf_model_url = "https://router.huggingface.co/hf-inference/models/black-forest-labs/FLUX.1-schnell"

        # í•œê¸€ í°íŠ¸ ì°¾ê¸°
        self.font_path = self._find_korean_font()

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("output/longform_images", exist_ok=True)
        os.makedirs("output/longform_videos", exist_ok=True)

    def _find_korean_font(self):
        """í•œê¸€ í°íŠ¸ ì°¾ê¸°"""
        possible_paths = [
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/System/Library/Fonts/Arial Unicode.ttf",
            "/Library/Fonts/NotoSansCJK.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/noto-cjk/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/nanum/NanumGothic.ttf",
            "/Windows/Fonts/malgun.ttf",
        ]

        for path in possible_paths:
            if os.path.exists(path):
                return path

        return None

    def create_video(self, script_data, audio_path, video_output_path,
                     sentence_timings=None, use_ai_background=True):
        """ë¡±í¼ ë¹„ë””ì˜¤ ìƒì„± ë©”ì¸ ë©”ì„œë“œ (thumbnail_path í•¨ê»˜ ë°˜í™˜)"""
        print("\nğŸ¬ ë¡±í¼ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘")
        self._thumbnail_path = None  # ì¸ë„¤ì¼ ê²½ë¡œ ì €ì¥ìš©

        audio_clip = None
        final_video = None
        try:
            # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
            print("ğŸ“Š ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...")
            audio_clip = AudioFileClip(audio_path)
            total_duration = audio_clip.duration
            print(f"âœ“ ì˜¤ë””ì˜¤ ê¸¸ì´: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")

            if total_duration < 600:
                print(f"âš ï¸ ê²½ê³ : ëª©í‘œ(10-15ë¶„)ë³´ë‹¤ ì§§ìŒ ({total_duration/60:.1f}ë¶„)")

            # 2. ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± (AI ë°°ê²½ + PIL ìë§‰)
            print("ğŸ¬ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± ì¤‘...")
            video_clips = self._create_video_clips_with_subtitles(
                script_data.get('title', ''),
                total_duration,
                sentence_timings
            )

            # 3. ìµœì¢… ë¹„ë””ì˜¤ í•©ì„±
            print("ğŸ”— ë¹„ë””ì˜¤ í•©ì„± ì¤‘...")
            final_video = concatenate_videoclips(video_clips)
            final_video = final_video.with_audio(audio_clip)

            # 4. ì €ì¥
            print(f"ğŸ’¾ ë¹„ë””ì˜¤ ì €ì¥ ì¤‘: {video_output_path}")
            os.makedirs(os.path.dirname(video_output_path), exist_ok=True)

            final_video.write_videofile(
                video_output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac'
            )

            print(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {video_output_path}")

            return video_output_path

        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if final_video:
                try:
                    final_video.close()
                except Exception:
                    pass
            if audio_clip:
                try:
                    audio_clip.close()
                except Exception:
                    pass

    def get_thumbnail_path(self):
        """ë§ˆì§€ë§‰ create_video í˜¸ì¶œ ì‹œ ìƒì„±ëœ ì¸ë„¤ì¼ ê²½ë¡œ ë°˜í™˜"""
        return self._thumbnail_path

    def _create_video_clips_with_subtitles(self, title, total_duration, sentence_timings):
        """Pexels ë°°ê²½ ì´ë¯¸ì§€ + ìŒì„± ì‹±í¬ ìë§‰ìœ¼ë¡œ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„±"""

        # â”€â”€ 1. ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± (30ì´ˆë§ˆë‹¤ êµì²´) â”€â”€
        num_images = max(1, int(total_duration / 30) + 1)
        print(f"ğŸ¨ ë°°ê²½ ì´ë¯¸ì§€ {num_images}ì¥ ì¤€ë¹„ ì¤‘ (30ì´ˆ ê°„ê²©)...")

        # ìë§‰ í…ìŠ¤íŠ¸ì—ì„œ AI í”„ë¡¬í”„íŠ¸ ìƒì„±ìš© í‚¤ì›Œë“œ ì¶”ì¶œ
        scene_texts = self._extract_scene_keywords(sentence_timings, total_duration, num_images)

        bg_images = []
        used_prompts = set()  # ì¤‘ë³µ í”„ë¡¬í”„íŠ¸ ë°©ì§€
        for i in range(num_images):
            img_path = None

            # 1ìˆœìœ„: HuggingFace AI ì¼ëŸ¬ìŠ¤íŠ¸
            if self.hf_token:
                prompt = self._build_illustration_prompt(
                    scene_texts[i] if i < len(scene_texts) else "",
                    used_prompts=used_prompts
                )
                img_path = self._generate_ai_illustration(prompt, i + 1)

            # 2ìˆœìœ„: Pexels ì‚¬ì§„
            if not img_path:
                keyword = self.IMAGE_KEYWORDS[i % len(self.IMAGE_KEYWORDS)]
                img_path = self._download_pexel_image(keyword, i + 1)

            # 3ìˆœìœ„: ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½
            if not img_path:
                img_path = self._create_gradient_background(i)

            bg_images.append(img_path)

        # â”€â”€ 2. ë°°ê²½ ì´ë¯¸ì§€ â†’ ImageClip (30ì´ˆë§ˆë‹¤ êµì²´) â”€â”€
        bg_clips = []
        for i, bg_path in enumerate(bg_images):
            start_time = i * 30
            end_time = min((i + 1) * 30, total_duration)
            dur = end_time - start_time

            if dur > 0:
                bg_clip = ImageClip(bg_path).with_duration(dur).with_start(start_time)
                bg_clips.append(bg_clip)

        # â”€â”€ 3. ìë§‰ ìƒì„± (PIL ê¸°ë°˜, ìƒ‰ìƒ/ë³¼ë“œ ì§€ì›) â”€â”€
        text_clips = []
        hook_text = None  # ì¸ë„¤ì¼ìš© í›„í‚¹ ë¬¸ì¥ ì €ì¥
        first_bg_path = bg_images[0] if bg_images else None
        if sentence_timings:
            import re
            print(f"ğŸ’¬ ìë§‰ {len(sentence_timings)}ê°œ ìƒì„± ì¤‘ (PIL ê¸°ë°˜, ìƒ‰ìƒ ê°•ì¡°)...")
            success_count = 0
            RED = (255, 0, 0, 255)
            WHITE = (255, 255, 255, 255)

            # ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œ ê²½ê³„ ê°ì§€
            # ì²« ë¬¸ì¥ = ì¸ì‚¬ë§ (RED), ë‘ ë²ˆì§¸ ë¬¸ì¥ = í›„í‚¹ (RED+BOLD) â†’ ì¸ë„¤ì¼ ì‚¬ìš©
            # ë§ˆì§€ë§‰ 2ë¬¸ì¥ = ì•„ì›ƒíŠ¸ë¡œ (RED)
            total_sents = len(sentence_timings)

            for i, timing in enumerate(sentence_timings):
                try:
                    start = timing['start']
                    end = timing['end']
                    text = timing['text'].strip()

                    if not text or start >= total_duration:
                        continue

                    # ìë§‰ ì§€ì† ì‹œê°„
                    if i + 1 < len(sentence_timings):
                        next_start = sentence_timings[i + 1]['start']
                        duration = next_start - start
                    else:
                        duration = min(end, total_duration) - start

                    if duration < 0.05:
                        continue

                    # ìƒ‰ìƒ/ë³¼ë“œ ê²°ì •
                    tc = WHITE
                    bold = False
                    if i == 0:  # ì²« ë¬¸ì¥ = ì¸ì‚¬ë§ (RED)
                        tc = RED
                    elif i == 1:  # ë‘ ë²ˆì§¸ ë¬¸ì¥ = ì§„ì§œ í›„í‚¹ (RED + BOLD)
                        tc = RED
                        bold = True
                        hook_text = text
                    elif i >= total_sents - 2:  # ë§ˆì§€ë§‰ 2ë¬¸ì¥ = ì•„ì›ƒíŠ¸ë¡œ RED
                        tc = RED

                    # PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„±
                    subtitle_img = self._create_subtitle_image(
                        text[:80], text_color=tc, is_bold=bold
                    )

                    clip = ImageClip(subtitle_img)
                    clip = clip.with_duration(duration)
                    clip = clip.with_start(start)
                    clip = clip.with_position(('center', self.height - 300))
                    text_clips.append(clip)
                    success_count += 1

                except Exception as e:
                    if i < 3:
                        print(f"  âš ï¸ ìë§‰ #{i+1} ì—ëŸ¬: {e}")
                    continue

            print(f"  âœ“ ìë§‰ {success_count}/{len(sentence_timings)}ê°œ ìƒì„± ì™„ë£Œ")

            # ì¸ë„¤ì¼ ìƒì„±: ì²« ë°°ê²½ ì´ë¯¸ì§€ + í›„í‚¹ ë¬¸ì¥ ì˜¤ë²„ë ˆì´
            if hook_text and first_bg_path:
                thumb_path = f"output/thumbnails/longform_thumb_{int(time.time())}.jpg"
                os.makedirs(os.path.dirname(thumb_path), exist_ok=True)
                self._thumbnail_path = self._create_hook_thumbnail(first_bg_path, hook_text, thumb_path)
        else:
            print("âš ï¸ sentence_timings ì—†ìŒ â†’ ìë§‰ ìƒëµ")

        # â”€â”€ 4. ëª¨ë“  í´ë¦½ í•©ì„± â”€â”€
        all_clips = bg_clips + text_clips

        if all_clips:
            try:
                composite = CompositeVideoClip(
                    all_clips, size=(self.width, self.height)
                ).with_duration(total_duration)
                return [composite]
            except Exception as e:
                print(f"âš ï¸ í•©ì„± ì—ëŸ¬: {e}")

        # í´ë°±: ê²€ì • ë°°ê²½
        return [ColorClip(
            size=(self.width, self.height), color=(0, 0, 0)
        ).with_duration(total_duration)]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  AI ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„± (HuggingFace)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _extract_scene_keywords(self, sentence_timings, total_duration, num_images):
        """ê° 30ì´ˆ êµ¬ê°„ì˜ ìë§‰ ì „ì²´ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (AI í”„ë¡¬í”„íŠ¸ìš©)"""
        scene_texts = []
        if not sentence_timings:
            return [""] * num_images

        for i in range(num_images):
            start_time = i * 30
            end_time = min((i + 1) * 30, total_duration)

            # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ìë§‰ í…ìŠ¤íŠ¸ ì „ì²´ ìˆ˜ì§‘
            segment_text = ""
            for timing in sentence_timings:
                t_start = timing.get('start', 0)
                if start_time <= t_start < end_time:
                    segment_text += timing.get('text', '') + " "

            scene_texts.append(segment_text.strip())

        return scene_texts

    def _build_illustration_prompt(self, scene_text, used_prompts=None):
        """ìë§‰ ë‚´ìš© ê¸°ë°˜ 3D ë Œë” ìŠ¤íƒ€ì¼ ì¼ëŸ¬ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base_style = (
            "3D render, cinematic lighting, detailed scene, "
            "modern digital art, high quality, "
            "dramatic composition, vivid colors, "
            "storytelling scene, emotional atmosphere, "
            "horizontal 16:9 aspect ratio, no text"
        )

        # í•œêµ­ì–´ â†’ ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘ (ì¥ë©´/ëŒ€ìƒ ë¬˜ì‚¬ ì¤‘ì‹¬)
        keyword_map = {
            # ì‚¬ëŒ/ê´€ê³„
            "ì‚¬ë‘": "two people in love, romantic scene",
            "í–‰ë³µ": "happy person smiling, warm atmosphere",
            "ìŠ¬í””": "person feeling sad, melancholy mood, tears",
            "í¬ë§": "person looking at hopeful horizon, light breaking through",
            "ê¿ˆ": "dreamy fantasy world, person dreaming",
            "ìš°ì •": "two friends together, warm friendship",
            "ê°€ì¡±": "family gathering, warm home scene",
            "ì—„ë§ˆ": "mother and child together, maternal love",
            "ì•„ë¹ ": "father figure, family bond",
            "ì•„ì´": "young child playing, innocent childhood",
            "ì²­ë…„": "young adult facing the world, determination",
            "í• ë¨¸ë‹ˆ": "elderly grandmother, wisdom and warmth",
            "í• ì•„ë²„ì§€": "elderly grandfather, gentle wisdom",
            "ì¹œêµ¬": "close friends sharing moment together",
            "ì—°ì¸": "couple in love, romantic scene",
            "ë¶€ë¶€": "married couple, warm domestic scene",
            "ì„ ìƒë‹˜": "teacher and student, learning moment",
            "í•™ìƒ": "student studying hard, school life",
            "ì§ì¥": "person at work, office scene",
            "ë™ë£Œ": "coworkers together, workplace bond",
            "ì´ë³„": "person saying farewell, bittersweet parting",
            "ë§Œë‚¨": "two people meeting for first time",
            "ëˆˆë¬¼": "person with tears, emotional crying scene",
            "ì›ƒìŒ": "person laughing joyfully, bright smile",
            "í¬ì˜¹": "two people embracing warmly, heartfelt hug",
            # ê°ì •/ìƒíƒœ
            "ê³ ë¯¼": "person deep in thought, contemplative",
            "í›„íšŒ": "person feeling regret, looking back",
            "ìš©ê¸°": "person standing brave, courageous pose",
            "ì„±ê³µ": "person achieving goal, celebration moment",
            "ì‹¤íŒ¨": "person fallen but getting back up, resilience",
            "ì™¸ë¡œ": "person alone, solitude scene",
            "ìŠ¤íŠ¸ë ˆìŠ¤": "person overwhelmed, pressure",
            "ìœ„ë¡œ": "person comforting another, consolation",
            "ê°ì‚¬": "person expressing gratitude, thankful moment",
            "ë¶„ë…¸": "person frustrated, angry emotion",
            "í™”í•´": "two people reconciling, making peace",
            # ì¥ì†Œ/í™˜ê²½
            "ë°”ë‹¤": "ocean waves, coastal scenery, sea horizon",
            "ì‚°": "mountain landscape, hiking path, mountain peak",
            "í•˜ëŠ˜": "vast sky with clouds, atmospheric sky",
            "ë³„": "starry night sky, constellation, night landscape",
            "ë¹„": "rainy scene, rain drops, umbrella in rain",
            "ëˆˆ": "snowy winter scene, falling snowflakes",
            "ë´„": "spring cherry blossoms, flowers blooming",
            "ì—¬ë¦„": "summer sunshine, bright blue sky",
            "ê°€ì„": "autumn red and golden leaves falling",
            "ê²¨ìš¸": "winter cold landscape, warm cozy indoor",
            "ë„ì‹œ": "city street scene, urban landscape",
            "ìˆ²": "forest path, trees and green nature",
            "ë°¤": "night scene with moonlight, dark atmosphere",
            "ì•„ì¹¨": "morning sunrise, dawn light, fresh start",
            "ë…¸ì„": "beautiful sunset, golden hour sky",
            "ê½ƒ": "flowers in bloom, garden scene",
            "ì§‘": "cozy house interior, warm home",
            "í•™êµ": "school building, campus, classroom",
            "ë³‘ì›": "hospital scene, medical setting",
            "ì¹´í˜": "cozy cafe interior, coffee shop",
            "ê¸¸": "long road ahead, path stretching forward",
            "ë‹¤ë¦¬": "bridge crossing over water, connection",
            # ìƒí™©/í–‰ë™
            "ì—¬í–‰": "person traveling, adventure journey",
            "ê³µë¶€": "person studying with books, learning",
            "ì¼": "person working hard, dedication",
            "ìŒì•…": "person playing music, musical instrument",
            "í¸ì§€": "person writing or reading a letter",
            "ì „í™”": "person making a phone call, conversation",
            "ì„ ë¬¼": "gift giving moment, wrapped present",
            "ì•½ì†": "two people making a promise, pinky promise",
            "ê¸°ë‹¤": "person waiting patiently, anticipation",
            "ë‹¬ë¦¬": "person running forward, determination",
            "ê±¸ì–´": "person walking along a path",
            "ì•‰ì•„": "person sitting peacefully, contemplation",
            # ì¶”ìƒ/ê¸°íƒ€
            "ì‹œê°„": "clock, time passing, hourglass, seasons changing",
            "ë¯¸ë˜": "futuristic hopeful horizon, path ahead",
            "ê³¼ê±°": "nostalgic vintage scene, old memories, sepia tone",
            "ì¸ìƒ": "life journey, path from young to old",
            "ë§ˆìŒ": "heart symbol, emotional inner world",
            "ê¸°ì–µ": "faded photos, memories floating, nostalgia",
            "ë³€í™”": "transformation scene, caterpillar to butterfly",
            "ì„ íƒ": "person at crossroads, making a choice",
            "ëˆ": "coins and savings, financial scene",
            "ê±´ê°•": "person exercising, healthy lifestyle",
        }

        # ìë§‰ì—ì„œ ë§¤ì¹­ë˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸° (ìµœëŒ€ 5ê°œ)
        matched_themes = []
        for ko, en in keyword_map.items():
            if ko in scene_text:
                matched_themes.append(en)

        # ì‚¬ëŒ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì‚¬ëŒì„ í¬í•¨í•˜ë„ë¡ ê°•ì¡°
        people_keywords = ["ì‚¬ëŒ", "ë‚¨ì", "ì—¬ì", "ê·¸", "ê·¸ë…€", "ë‚˜", "ìš°ë¦¬", "ì €", "ë„ˆ",
                          "ì—„ë§ˆ", "ì•„ë¹ ", "ì•„ì´", "ì¹œêµ¬", "ì„ ìƒ", "í•™ìƒ", "ë¶€ëª¨", "í˜•", "ëˆ„ë‚˜",
                          "ë™ìƒ", "ì–¸ë‹ˆ", "ì˜¤ë¹ ", "í• ë¨¸ë‹ˆ", "í• ì•„ë²„ì§€", "ì•„ì €ì”¨", "ì•„ì¤Œë§ˆ"]
        has_people = any(kw in scene_text for kw in people_keywords)

        if matched_themes:
            # ì¤‘ë³µ ë°©ì§€: used_promptsì— ì´ë¯¸ ìˆëŠ” í…Œë§ˆ ì œì™¸
            unique_themes = matched_themes[:5]
            theme = ", ".join(unique_themes)
            people_note = ", people characters prominently featured" if has_people else ""
            prompt = f"{theme}{people_note}, {base_style}"
        else:
            # ë§¤ì¹­ ì—†ìœ¼ë©´ ì¥ë©´ í…ìŠ¤íŠ¸ ì¼ë¶€ë¥¼ ì§ì ‘ ì‚¬ìš©
            # ìë§‰ì—ì„œ ëª…ì‚¬/í‚¤ì›Œë“œ ëŠë‚Œìœ¼ë¡œ ì•ë¶€ë¶„ ì¶”ì¶œ
            hint = scene_text[:80].replace('\n', ' ').strip()
            people_note = ", with people characters" if has_people else ""
            default_scenes = [
                "peaceful village at sunset, warm community",
                "cozy room with window light, person reading",
                "forest clearing with sunbeams, magical atmosphere",
                "ocean cliff overlooking vast sea, contemplation",
                "city rooftop at twilight, person gazing at skyline",
                "flower garden in gentle breeze, peaceful moment",
                "mountain path at dawn, person hiking upward",
                "rain falling on window, person inside warm room",
                "ancient tree in meadow, person sitting beneath",
                "train platform, person waiting for departure",
                "library filled with books, quiet study scene",
                "riverside at golden hour, person fishing peacefully",
            ]
            scene = default_scenes[hash(hint) % len(default_scenes)]
            prompt = f"{scene}{people_note}, {base_style}"

        # ì¤‘ë³µ í”„ë¡¬í”„íŠ¸ ë°©ì§€
        if used_prompts is not None:
            if prompt in used_prompts:
                # ë³€í˜• ì¶”ê°€ë¡œ ì¤‘ë³µ íšŒí”¼
                variations = [
                    "wide angle view, ", "close up view, ",
                    "bird eye view, ", "from behind, ",
                    "evening version, ", "morning version, ",
                    "different perspective, ", "profile view, ",
                ]
                for v in variations:
                    new_prompt = v + prompt
                    if new_prompt not in used_prompts:
                        prompt = new_prompt
                        break
            used_prompts.add(prompt)

        return prompt

    def _generate_ai_illustration(self, prompt, index):
        """HuggingFace FLUX.1-schnellë¡œ AI ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„±"""
        try:
            headers = {
                "Authorization": f"Bearer {self.hf_token}",
                "Content-Type": "application/json",
            }
            payload = {
                "inputs": prompt,
                "parameters": {"width": 1344, "height": 768}
            }

            print(f"  [{index}] AI ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
            response = requests.post(
                self.hf_model_url,
                json=payload,
                headers=headers,
                timeout=60,
            )

            ct = response.headers.get("content-type", "")
            if response.status_code == 200 and "image" in ct:
                from io import BytesIO
                img = Image.open(BytesIO(response.content))

                # Center cropìœ¼ë¡œ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
                img_cropped = self._center_crop_resize(img)
                output_path = f"output/longform_images/bg_ai_{index}_{int(time.time())}.jpg"
                img_cropped.save(output_path, "JPEG", quality=90)

                fsize = os.path.getsize(output_path) // 1024
                print(f"  âœ“ [{index}] AI ì¼ëŸ¬ìŠ¤íŠ¸ ì™„ë£Œ ({fsize}KB)")
                return output_path
            elif response.status_code == 503:
                print(f"  âš ï¸ [{index}] ëª¨ë¸ ë¡œë”© ì¤‘... Pexels í´ë°±")
            else:
                print(f"  âš ï¸ [{index}] AI ìƒì„± ì‹¤íŒ¨ ({response.status_code}) â†’ Pexels í´ë°±")

            return None

        except Exception as e:
            print(f"  âš ï¸ [{index}] AI ìƒì„± ì—ëŸ¬: {e} â†’ Pexels í´ë°±")
            return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ë°°ê²½ ì´ë¯¸ì§€ ê´€ë ¨ (Pexels í´ë°±)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _download_pexel_image(self, keyword, index):
        """Pexels APIì—ì„œ ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""

        if not self.pexels_api_key:
            print(f"  [{index}] âš ï¸ Pexels API í‚¤ ì—†ìŒ â†’ ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½ ì‚¬ìš©")
            return None

        try:
            headers = {"Authorization": self.pexels_api_key}
            params = {
                "query": keyword,
                "per_page": 15,
                "orientation": "landscape",
                "size": "large",
            }

            print(f"  [{index}] Pexels ê²€ìƒ‰: {keyword}...")
            response = requests.get(
                "https://api.pexels.com/v1/search",
                headers=headers,
                params=params,
                timeout=15,
            )

            if response.status_code == 200:
                data = response.json()
                photos = data.get("photos", [])

                if photos:
                    photo = random.choice(photos)
                    img_url = photo["src"]["landscape"]

                    img_resp = requests.get(img_url, timeout=20)
                    if img_resp.status_code == 200:
                        output_path = f"output/longform_images/bg_pexel_{index}_{int(time.time())}.jpg"
                        with open(output_path, 'wb') as f:
                            f.write(img_resp.content)

                        # Center cropìœ¼ë¡œ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
                        try:
                            img = Image.open(output_path)
                            img = self._center_crop_resize(img)
                            img.save(output_path, 'JPEG', quality=90)
                        except Exception:
                            pass

                        print(f"  âœ“ [{index}] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                        return output_path
                    else:
                        print(f"  âš ï¸ [{index}] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {img_resp.status_code}")
                else:
                    print(f"  âš ï¸ [{index}] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {keyword}")
            elif response.status_code == 401:
                print(f"  âš ï¸ [{index}] Pexels API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
            else:
                print(f"  âš ï¸ [{index}] API ì—ëŸ¬: {response.status_code}")

            return None

        except Exception as e:
            print(f"  âš ï¸ [{index}] ë‹¤ìš´ë¡œë“œ ì—ëŸ¬: {e}")
            return None

    def _create_gradient_background(self, index):
        """ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± (Pexels ì‹¤íŒ¨ ì‹œ í´ë°±)"""
        colors = [
            ((15, 25, 50), (40, 70, 130)),   # ì§„í•œ íŒŒë‘
            ((30, 15, 45), (80, 40, 120)),   # ì§„í•œ ë³´ë¼
            ((45, 30, 15), (120, 80, 40)),   # ì§„í•œ ê°ˆìƒ‰
            ((15, 40, 30), (40, 110, 80)),   # ì§„í•œ ì²­ë¡
            ((40, 15, 25), (110, 40, 70)),   # ì§„í•œ ë¶„í™
            ((10, 10, 30), (30, 30, 90)),    # ì§™ì€ ë‚¨ìƒ‰
        ]

        c1, c2 = colors[index % len(colors)]

        img = Image.new('RGB', (self.width, self.height))
        draw = ImageDraw.Draw(img)

        for y in range(self.height):
            r = y / self.height
            color = tuple(int(c1[j] + (c2[j] - c1[j]) * r) for j in range(3))
            draw.line([(0, y), (self.width, y)], fill=color)

        path = f"output/longform_images/bg_grad_{index}_{int(time.time())}.jpg"
        img.save(path, 'JPEG', quality=90)
        print(f"  âœ“ [{index+1}] ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½ ìƒì„±")
        return path

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  PIL ìë§‰ + ì¸ë„¤ì¼
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _load_font(self, font_size):
        """í•œê¸€ í°íŠ¸ ë¡œë“œ"""
        font = None
        try:
            if self.font_path:
                font = ImageFont.truetype(self.font_path, font_size)
            else:
                fallback_fonts = [
                    "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
                    "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
                    "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                ]
                for fp in fallback_fonts:
                    if os.path.exists(fp):
                        try:
                            font = ImageFont.truetype(fp, font_size)
                            break
                        except:
                            continue
        except:
            pass
        if not font:
            font = ImageFont.load_default()
        return font

    def _create_subtitle_image(self, text, font_size=48, text_color=(255, 255, 255, 255), is_bold=False):
        """PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„± (í•œê¸€ ì§€ì›, ìƒ‰ìƒ/ë³¼ë“œ)"""
        temp_img = Image.new('RGBA', (self.width, 300), (0, 0, 0, 0))
        temp_draw = ImageDraw.Draw(temp_img)
        font = self._load_font(font_size)

        # ë‹¨ì–´ ë‹¨ìœ„ ì¤„ë°”ê¿ˆ
        max_width = self.width - 200
        lines = []
        current_line = ""
        words = text.split(' ')

        for word in words:
            test_line = current_line + (' ' if current_line else '') + word
            bbox = temp_draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                    current_line = word
                else:
                    lines.append(word)
                    current_line = ""
        if current_line:
            lines.append(current_line)

        line_height = font_size + 20
        padding = 15
        text_bg_height = len(lines) * line_height + (padding * 2)
        img_height = text_bg_height + 30

        img = Image.new('RGBA', (self.width, img_height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)

        # ë°˜íˆ¬ëª… ê²€ì • ë°•ìŠ¤
        box_top = 15
        box_bottom = box_top + text_bg_height
        box_left = 60
        box_right = self.width - 60

        box_img = Image.new('RGBA', (self.width, img_height), (0, 0, 0, 0))
        box_draw = ImageDraw.Draw(box_img)
        box_draw.rectangle([(box_left, box_top), (box_right, box_bottom)], fill=(0, 0, 0, 200))
        box_draw.rectangle([(box_left, box_top), (box_right, box_bottom)], outline=(0, 0, 0, 255), width=2)
        img = Image.alpha_composite(img, box_img)
        draw = ImageDraw.Draw(img)

        y_offset = box_top + padding
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (self.width - text_width) // 2

            # ê·¸ë¦¼ì
            for offset in [(3, 3), (2, 2)]:
                draw.text((x + offset[0], y_offset + offset[1]), line, font=font, fill=(0, 0, 0, 200))
            # ì™¸ê³½ì„ 
            for dx in [-2, -1, 0, 1, 2]:
                for dy in [-2, -1, 0, 1, 2]:
                    if dx != 0 or dy != 0:
                        draw.text((x + dx, y_offset + dy), line, font=font, fill=(0, 0, 0, 255))
            # ë³¸ë¬¸
            draw.text((x, y_offset), line, font=font, fill=text_color)
            if is_bold:
                draw.text((x + 1, y_offset), line, font=font, fill=text_color)
                draw.text((x + 2, y_offset), line, font=font, fill=text_color)
            y_offset += line_height

        return np.array(img)

    def _create_hook_thumbnail(self, bg_image_path, hook_text, output_path):
        """ë°°ê²½ ì´ë¯¸ì§€ + í›„í‚¹ ë¬¸ì¥ ì˜¤ë²„ë ˆì´ë¡œ ì¸ë„¤ì¼ ìƒì„±"""
        try:
            bg = Image.open(bg_image_path).convert('RGB')
            bg = bg.resize((self.width, self.height), Image.LANCZOS)
            draw = ImageDraw.Draw(bg)

            font_size = 72
            font = self._load_font(font_size)

            # ë‹¨ì–´ ë‹¨ìœ„ ì¤„ë°”ê¿ˆ
            max_width = self.width - 200
            lines = []
            current_line = ""
            for word in hook_text.split(' '):
                test_line = current_line + (' ' if current_line else '') + word
                bbox = draw.textbbox((0, 0), test_line, font=font)
                if bbox[2] - bbox[0] <= max_width:
                    current_line = test_line
                else:
                    if current_line:
                        lines.append(current_line)
                    current_line = word
            if current_line:
                lines.append(current_line)

            line_height = font_size + 25
            total_text_h = len(lines) * line_height
            y_start = (self.height - total_text_h) // 2

            # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤
            pad = 30
            box_top = y_start - pad
            box_bottom = y_start + total_text_h + pad
            overlay = Image.new('RGBA', (self.width, self.height), (0, 0, 0, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            overlay_draw.rectangle(
                [(80, box_top), (self.width - 80, box_bottom)],
                fill=(0, 0, 0, 160)
            )
            bg = Image.alpha_composite(bg.convert('RGBA'), overlay).convert('RGB')
            draw = ImageDraw.Draw(bg)

            # í›„í‚¹ ë¬¸ì¥ ê·¸ë¦¬ê¸° (#FF0000 + ë³¼ë“œ)
            RED = (255, 0, 0)
            for idx, line in enumerate(lines):
                bbox = draw.textbbox((0, 0), line, font=font)
                tw = bbox[2] - bbox[0]
                x = (self.width - tw) // 2
                y = y_start + idx * line_height

                # ê·¸ë¦¼ì + ì™¸ê³½ì„ 
                for ox, oy in [(4, 4), (3, 3), (2, 2)]:
                    draw.text((x + ox, y + oy), line, font=font, fill=(0, 0, 0))
                for dx in [-3, -2, -1, 0, 1, 2, 3]:
                    for dy in [-3, -2, -1, 0, 1, 2, 3]:
                        if dx != 0 or dy != 0:
                            draw.text((x + dx, y + dy), line, font=font, fill=(0, 0, 0))
                # ë¹¨ê°„ ë³¸ë¬¸ + ë³¼ë“œ
                draw.text((x, y), line, font=font, fill=RED)
                draw.text((x + 1, y), line, font=font, fill=RED)
                draw.text((x + 2, y), line, font=font, fill=RED)

            bg.save(output_path, 'JPEG', quality=95)
            print(f"  âœ… í›„í‚¹ ì¸ë„¤ì¼ ìƒì„±: {output_path}")
            return output_path
        except Exception as e:
            print(f"  âš ï¸ ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ìœ í‹¸ë¦¬í‹°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _hex_to_rgb(self, hex_color):
        """Hex ìƒ‰ìƒì„ RGB íŠœí”Œë¡œ ë³€í™˜"""
        hex_color = hex_color.lstrip('#')
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

    def _center_crop_resize(self, img):
        """Center crop ë°©ì‹ìœ¼ë¡œ ë¹„ìœ¨ ìœ ì§€í•˜ë©° target í•´ìƒë„ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ"""
        target_w, target_h = self.width, self.height
        target_ratio = target_w / target_h  # 16:9 = 1.778
        img_w, img_h = img.size
        img_ratio = img_w / img_h

        if img_ratio > target_ratio:
            # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ â†’ ì¢Œìš° í¬ë¡­
            new_w = int(img_h * target_ratio)
            left = (img_w - new_w) // 2
            img = img.crop((left, 0, left + new_w, img_h))
        else:
            # ì´ë¯¸ì§€ê°€ ë” ë†’ìŒ â†’ ìƒí•˜ í¬ë¡­
            new_h = int(img_w / target_ratio)
            top = (img_h - new_h) // 2
            img = img.crop((0, top, img_w, top + new_h))

        return img.resize((target_w, target_h), Image.LANCZOS)


if __name__ == "__main__":
    gen = LongformVideoGenerator()
    print(f"âœ“ í•´ìƒë„: {gen.width}x{gen.height}")
    print(f"âœ“ í°íŠ¸: {gen.font_path}")
    print(f"âœ“ Pexels API: {'ì„¤ì •ë¨' if gen.pexels_api_key else 'ë¯¸ì„¤ì •'}")
    print(f"âœ“ HuggingFace: {'ì„¤ì •ë¨' if gen.hf_token else 'ë¯¸ì„¤ì •'}")
