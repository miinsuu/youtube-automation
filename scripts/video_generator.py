"""
ë¹„ë””ì˜¤ ìƒì„± ëª¨ë“ˆ
MoviePyë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±, ë°°ê²½, ìë§‰ì„ í•©ì„±í•˜ì—¬ ìµœì¢… ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import os
import requests
import subprocess
from moviepy import (
    ColorClip, AudioFileClip, CompositeVideoClip, 
    TextClip, concatenate_videoclips, ImageClip, VideoClip
)
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import numpy as np


class VideoGenerator:
    def __init__(self, config_path="config/config.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        # ë¹„ë””ì˜¤ ì„¤ì •
        res = self.config['video']['resolution'].split('x')
        self.width = int(res[0])
        self.height = int(res[1])
        self.fps = self.config['video']['fps']
        self.bg_color = self.config['video']['background_color']
        self.text_color = self.config['video']['text_color']
        self.accent_color = self.config['video']['accent_color']
        
        # í•œê¸€ í°íŠ¸ ì°¾ê¸°
        self.font_path = self._find_korean_font()
    
    def _find_korean_font(self):
        """ì‹œìŠ¤í…œì—ì„œ í•œê¸€ í°íŠ¸ ì°¾ê¸°"""
        # macOS í°íŠ¸ ê²½ë¡œë“¤
        font_paths = [
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/System/Library/Fonts/Supplemental/AppleGothic.ttf",
            "/Library/Fonts/AppleGothic.ttf",
            "/System/Library/Fonts/Helvetica.ttc",
            # Linux í°íŠ¸ ê²½ë¡œë“¤
            "/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf",
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
        ]
        
        for path in font_paths:
            if os.path.exists(path):
                print(f"âœ… í•œê¸€ í°íŠ¸ ë°œê²¬: {path}")
                return path
        
        print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        return None
    
    def extract_keywords_from_script(self, script_text):
        """ëŒ€ë³¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re
        
        # í•œê¸€-ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘ (í™•ì¥)
        keyword_map = {
            # ê³¼í•™/ê¸°ìˆ 
            "ë‡Œ": "brain neuroscience",
            "ìš°ì£¼": "space galaxy stars",
            "í–‰ì„±": "planet solar system",
            "ë¸”ë™í™€": "black hole space",
            "íƒœì–‘": "sun solar",
            "ë‹¬": "moon lunar",
            "ë³„": "stars night sky",
            "ê³¼í•™": "science laboratory",
            "ì‹¤í—˜": "experiment laboratory",
            "DNA": "DNA genetics",
            "ì„¸í¬": "cell biology",
            "ì›ì": "atom physics",
            "ì—ë„ˆì§€": "energy power",
            "ì „ê¸°": "electricity lightning",
            "ë¡œë´‡": "robot technology",
            "ì¸ê³µì§€ëŠ¥": "artificial intelligence AI",
            "ì»´í“¨í„°": "computer technology",
            
            # ìì—°/ë™ë¬¼
            "ë°”ë‹¤": "ocean underwater sea",
            "ì‚°": "mountain nature",
            "ìˆ²": "forest trees nature",
            "ë™ë¬¼": "animals wildlife",
            "ìƒˆ": "birds flying",
            "ë¬¼ê³ ê¸°": "fish underwater",
            "ê³ ë˜": "whale ocean",
            "ìƒì–´": "shark ocean",
            "ì‚¬ì": "lion wildlife",
            "í˜¸ë‘ì´": "tiger wildlife",
            "ê³µë£¡": "dinosaur prehistoric",
            "ê³¤ì¶©": "insects macro",
            "ê½ƒ": "flowers nature",
            "ë‚˜ë¬´": "trees forest",
            
            # ì¸ì²´/ê±´ê°•
            "ì‹¬ì¥": "heart medical",
            "ëˆˆ": "eye vision",
            "ê·€": "ear hearing",
            "í”¼": "blood medical",
            "ê·¼ìœ¡": "muscle fitness",
            "ë¼ˆ": "skeleton bones",
            "ì¸ì²´": "human body anatomy",
            "ê±´ê°•": "health wellness",
            "ìš´ë™": "exercise fitness",
            "ìˆ˜ë©´": "sleep rest",
            "ìŒì‹": "food nutrition",
            
            # ì—­ì‚¬/ë¬¸í™”
            "ì—­ì‚¬": "history ancient civilization",
            "ì „ìŸ": "war battle history",
            "ì™•": "king royal castle",
            "í”¼ë¼ë¯¸ë“œ": "pyramid egypt ancient",
            "ë¡œë§ˆ": "rome ancient architecture",
            "ê·¸ë¦¬ìŠ¤": "greece ancient temple",
            "ì¤‘ì„¸": "medieval castle knight",
            "ë¬¸ëª…": "civilization ancient",
            
            # ì„¸ê³„/ì§€ë¦¬
            "ì„¸ê³„": "world globe earth",
            "ì§€êµ¬": "earth planet",
            "ë‚˜ë¼": "countries flags world",
            "ë„ì‹œ": "city skyline urban",
            "ì‚¬ë§‰": "desert landscape",
            "ë¶ê·¹": "arctic ice polar",
            "í™”ì‚°": "volcano lava",
            "ì§€ì§„": "earthquake disaster",
            
            # ì‹¬ë¦¬/ê°ì •
            "ì‹¬ë¦¬": "psychology mind brain",
            "ê°ì •": "emotions feelings",
            "ê¸°ì–µ": "memory brain",
            "ê¿ˆ": "dream sleep",
            "í–‰ë³µ": "happiness joy",
            "ê³µí¬": "fear horror dark",
            "ì‚¬ë‘": "love heart romance",
            
            # ê¸°ë¡/ìˆ«ì
            "ê¸°ë¡": "record achievement trophy",
            "ì„¸ê³„ê¸°ë¡": "world record champion",
            "ìµœê³ ": "best champion winner",
            "ìµœì´ˆ": "first pioneer discovery",
            "ìˆ«ì": "numbers mathematics",
            "í†µê³„": "statistics data chart",
        }
        
        # ëŒ€ë³¸ì—ì„œ ë§¤ì¹­ë˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
        found_keywords = []
        for kr, en in keyword_map.items():
            if kr in script_text:
                found_keywords.append(en)
        
        # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        if not found_keywords:
            found_keywords = ["abstract dark background"]
        
        return found_keywords

    def download_background_images(self, keywords, count=3, script_text=""):
        """Pexels APIë¡œ ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ëŒ€ë³¸ ê¸°ë°˜ í‚¤ì›Œë“œ ì‚¬ìš©)"""
        images = []
        
        # Pexels API í‚¤
        pexels_api_key = "***REMOVED***"
        
        try:
            # ëŒ€ë³¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            if script_text:
                search_queries = self.extract_keywords_from_script(script_text)
            else:
                # ê¸°ì¡´ ë°©ì‹ (í† í”½ ê¸°ë°˜)
                keyword_map = {
                    "ì—­ì‚¬": "history ancient",
                    "ê³¼í•™": "science technology",
                    "ìš°ì£¼": "space galaxy",
                    "ë™ë¬¼": "animals nature",
                    "ì‹¬ë¦¬í•™": "brain mind",
                    "ì¸ì²´": "human body medical",
                    "ê¸°ìˆ ": "technology future",
                    "ì„¸ê³„": "world travel"
                }
                
                search_queries = ["abstract dark background"]
                for kr, en in keyword_map.items():
                    if kr in keywords:
                        search_queries = [en]
                        break
            
            headers = {"Authorization": pexels_api_key}
            
            # ê° í‚¤ì›Œë“œë³„ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ (ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í™•ë³´)
            images_per_query = max(1, count // len(search_queries[:3]))
            
            for query in search_queries[:5]:  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
                if len(images) >= count:
                    break
                    
                url = f"https://api.pexels.com/v1/search?query={query}&per_page={images_per_query}&orientation=portrait"
                
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    for photo in data.get('photos', []):
                        if len(images) >= count:
                            break
                        img_url = photo['src']['large2x']
                        img_response = requests.get(img_url, timeout=10)
                        if img_response.status_code == 200:
                            from io import BytesIO
                            img = Image.open(BytesIO(img_response.content))
                            img = self._resize_and_crop(img)
                            images.append(img)
                            print(f"âœ… ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ({query}): {len(images)}/{count}")
            
        except Exception as e:
            print(f"âš ï¸ ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ë¬´ë‚œí•œ ì´ë¯¸ì§€ë¡œ ì±„ìš°ê¸° (ê·¸ë¼ë””ì–¸íŠ¸ ëŒ€ì‹ )
        fallback_queries = ["dark abstract", "night sky", "nature landscape", "cinematic background", "dramatic lighting"]
        fallback_idx = 0
        
        while len(images) < count and fallback_idx < len(fallback_queries):
            try:
                query = fallback_queries[fallback_idx]
                print(f"ğŸ“· ì¶”ê°€ ë°°ê²½ ê²€ìƒ‰ ({query})...")
                
                url = f"https://api.pexels.com/v1/search?query={query}&per_page=3&orientation=portrait"
                headers = {"Authorization": pexels_api_key}
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    for photo in data.get('photos', []):
                        if len(images) >= count:
                            break
                        img_url = photo['src']['large2x']
                        img_response = requests.get(img_url, timeout=10)
                        if img_response.status_code == 200:
                            from io import BytesIO
                            img = Image.open(BytesIO(img_response.content))
                            img = self._resize_and_crop(img)
                            images.append(img)
                            print(f"âœ… ì¶”ê°€ ë°°ê²½ ì´ë¯¸ì§€: {len(images)}/{count}")
            except:
                pass
            fallback_idx += 1
        
        # ê·¸ë˜ë„ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ìœ¼ë¡œ ì•„ë¬´ ì¸ê¸° ì´ë¯¸ì§€ë¼ë„ ê°€ì ¸ì˜¤ê¸°
        if len(images) < count:
            try:
                print("ğŸ“· ì¸ê¸° ì´ë¯¸ì§€ì—ì„œ ì¶”ê°€ ê²€ìƒ‰...")
                url = f"https://api.pexels.com/v1/curated?per_page={count - len(images)}"
                headers = {"Authorization": pexels_api_key}
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    for photo in data.get('photos', []):
                        if len(images) >= count:
                            break
                        img_url = photo['src']['large2x']
                        img_response = requests.get(img_url, timeout=10)
                        if img_response.status_code == 200:
                            from io import BytesIO
                            img = Image.open(BytesIO(img_response.content))
                            img = self._resize_and_crop(img)
                            images.append(img)
                            print(f"âœ… ì¸ê¸° ì´ë¯¸ì§€ ì¶”ê°€: {len(images)}/{count}")
            except:
                pass
        
        return images
    
    def _resize_and_crop(self, img):
        """ì´ë¯¸ì§€ë¥¼ ì„¸ë¡œ í˜•ì‹ìœ¼ë¡œ í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ"""
        target_ratio = self.height / self.width
        img_ratio = img.height / img.width
        
        if img_ratio > target_ratio:
            # ì´ë¯¸ì§€ê°€ ë” ì„¸ë¡œë¡œ ê¹€ - ìœ„ì•„ë˜ ìë¥´ê¸°
            new_height = int(img.width * target_ratio)
            top = (img.height - new_height) // 2
            img = img.crop((0, top, img.width, top + new_height))
        else:
            # ì´ë¯¸ì§€ê°€ ë” ê°€ë¡œë¡œ ê¹€ - ì¢Œìš° ìë¥´ê¸°
            new_width = int(img.height / target_ratio)
            left = (img.width - new_width) // 2
            img = img.crop((left, 0, left + new_width, img.height))
        
        img = img.resize((self.width, self.height), Image.LANCZOS)
        
        # ì–´ë‘¡ê²Œ ì²˜ë¦¬ (ìë§‰ì´ ì˜ ë³´ì´ë„ë¡)
        enhancer = Image.new('RGBA', img.size, (0, 0, 0, 150))
        img = img.convert('RGBA')
        img = Image.alpha_composite(img, enhancer)
        
        return img.convert('RGB')
    
    def _create_gradient_image(self):
        """ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±"""
        img = Image.new('RGB', (self.width, self.height))
        draw = ImageDraw.Draw(img)
        
        # ê·¸ë¼ë””ì–¸íŠ¸ ìƒ‰ìƒ
        colors = [
            ((26, 26, 46), (46, 46, 86)),
            ((20, 30, 48), (36, 59, 85)),
            ((15, 32, 39), (32, 58, 67)),
        ]
        
        import random
        c1, c2 = random.choice(colors)
        
        for i in range(self.height):
            ratio = i / self.height
            r = int(c1[0] + (c2[0] - c1[0]) * ratio)
            g = int(c1[1] + (c2[1] - c1[1]) * ratio)
            b = int(c1[2] + (c2[2] - c1[2]) * ratio)
            draw.line([(0, i), (self.width, i)], fill=(r, g, b))
        
        return img

    def create_background_video(self, images, duration):
        """ë°°ê²½ ì´ë¯¸ì§€ë“¤ë¡œ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± (Ken Burns íš¨ê³¼)"""
        if not images:
            return ColorClip(
                size=(self.width, self.height),
                color=(26, 26, 46),
                duration=duration
            ).with_fps(self.fps)
        
        clips = []
        time_per_image = duration / len(images)
        
        for i, img in enumerate(images):
            # PIL ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(img)
            
            # ImageClip ìƒì„±
            clip = ImageClip(img_array).with_duration(time_per_image)
            clip = clip.with_start(i * time_per_image)
            clips.append(clip)
        
        return CompositeVideoClip(clips, size=(self.width, self.height)).with_fps(self.fps)
    
    def _create_subtitle_image(self, text, font_size=80):
        """PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„± (í•œê¸€ ì§€ì›)"""
        # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€
        img = Image.new('RGBA', (self.width, 400), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        
        # í°íŠ¸ ë¡œë“œ
        try:
            if self.font_path:
                font = ImageFont.truetype(self.font_path, font_size)
            else:
                font = ImageFont.load_default()
        except:
            font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (ìµœëŒ€ 2ì¤„)
        max_width = self.width - 120
        lines = []
        current_line = ""
        
        for char in text:
            test_line = current_line + char
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = char
                # ìµœëŒ€ 2ì¤„ê¹Œì§€ë§Œ
                if len(lines) >= 2:
                    break
        if current_line and len(lines) < 2:
            lines.append(current_line)
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ê·¸ë¦¼ì + ì™¸ê³½ì„  + í°ìƒ‰ ë³¸ë¬¸)
        y_offset = 30
        line_height = font_size + 25
        
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (self.width - text_width) // 2
            
            # ê·¸ë¦¼ì íš¨ê³¼
            for offset in [(4, 4), (3, 3), (2, 2)]:
                draw.text((x + offset[0], y_offset + offset[1]), line, font=font, fill=(0, 0, 0, 200))
            
            # ì™¸ê³½ì„ 
            for dx in [-2, -1, 0, 1, 2]:
                for dy in [-2, -1, 0, 1, 2]:
                    if dx != 0 or dy != 0:
                        draw.text((x + dx, y_offset + dy), line, font=font, fill=(0, 0, 0, 255))
            
            # í°ìƒ‰ ë³¸ë¬¸
            draw.text((x, y_offset), line, font=font, fill=(255, 255, 255, 255))
            y_offset += line_height
        
        return np.array(img)
    
    def create_subtitle_clips(self, script_text, audio_duration, sentence_timings=None):
        """ìë§‰ í´ë¦½ ìƒì„± (PIL ê¸°ë°˜, í•œê¸€ ì§€ì›, ìŒì„± íƒ€ì´ë° ê¸°ë°˜)"""
        import re
        
        # ìŒì„± íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
        if sentence_timings and len(sentence_timings) > 0:
            print(f"   ğŸ“ ìŒì„± íƒ€ì´ë° ê¸°ë°˜ ìë§‰ ìƒì„± ({len(sentence_timings)}ê°œ ë¬¸ì¥)")
            clips = []
            
            for i, timing in enumerate(sentence_timings):
                text = timing["text"]
                start_time = timing["start"]
                # ë‹¤ìŒ ë¬¸ì¥ ì‹œì‘ê¹Œì§€ ë˜ëŠ” ì˜¤ë””ì˜¤ ëê¹Œì§€
                if i < len(sentence_timings) - 1:
                    end_time = sentence_timings[i + 1]["start"]
                else:
                    end_time = audio_duration
                
                duration = end_time - start_time
                
                # ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ ë¶„ë¦¬
                if len(text) > 40:
                    # ì‰¼í‘œë‚˜ ì¡°ì‚¬ ìœ„ì¹˜ì—ì„œ ë¶„ë¦¬í•˜ì—¬ ë³„ë„ í‘œì‹œ
                    pass  # í•œ ìë§‰ìœ¼ë¡œ í‘œì‹œí•˜ë˜ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
                
                # PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„±
                subtitle_img = self._create_subtitle_image(text)
                
                # ImageClipìœ¼ë¡œ ë³€í™˜
                clip = ImageClip(subtitle_img)
                clip = clip.with_duration(duration)
                clip = clip.with_start(start_time)
                clip = clip.with_position(('center', int(self.height * 0.30)))
                
                clips.append(clip)
            
            return clips
        
        # íƒ€ì´ë° ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ (ê· ë“± ë¶„ë°°)
        print("   ğŸ“ ê· ë“± ë¶„ë°° ë°©ì‹ ìë§‰ ìƒì„±")
        
        # ë¬¸ë§¥ìƒ ìì—°ìŠ¤ëŸ¬ìš´ ìœ„ì¹˜ì—ì„œ ìë§‰ ë¶„ë¦¬
        # 1. ë¨¼ì € ë¬¸ì¥ ë¶€í˜¸ë¡œ ë¶„ë¦¬
        # 2. ê¸´ ë¬¸ì¥ì€ ì¡°ì‚¬/ì–´ë¯¸ ìœ„ì¹˜ì—ì„œ ì¶”ê°€ ë¶„ë¦¬
        
        # ë¬¸ì¥ ë¶€í˜¸ë¡œ 1ì°¨ ë¶„ë¦¬ (ë¶€í˜¸ ìœ ì§€)
        raw_segments = re.split(r'([.!?]+\s*)', script_text)
        segments = []
        
        for i in range(0, len(raw_segments) - 1, 2):
            text = raw_segments[i]
            punct = raw_segments[i + 1] if i + 1 < len(raw_segments) else ""
            if text.strip():
                segments.append(text.strip() + punct.strip())
        
        # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
        if len(raw_segments) % 2 == 1 and raw_segments[-1].strip():
            segments.append(raw_segments[-1].strip())
        
        # ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ ì‰¼í‘œë‚˜ ìì—°ìŠ¤ëŸ¬ìš´ ìœ„ì¹˜ì—ì„œ ë¶„ë¦¬
        final_segments = []
        for seg in segments:
            if len(seg) > 35:  # 35ì ì´ìƒì´ë©´ ë¶„ë¦¬ ì‹œë„
                # ì‰¼í‘œë¡œ ë¶„ë¦¬
                if ',' in seg:
                    parts = seg.split(',')
                    for j, part in enumerate(parts):
                        part = part.strip()
                        if part:
                            if j < len(parts) - 1:
                                final_segments.append(part + ',')
                            else:
                                final_segments.append(part)
                # ì¡°ì‚¬ ìœ„ì¹˜ì—ì„œ ë¶„ë¦¬ (ëŠ”, ì€, ì´, ê°€, ë¥¼, ì„, ì—ì„œ, ìœ¼ë¡œ ë“±)
                elif len(seg) > 40:
                    # ì¤‘ê°„ ì§€ì  ê·¼ì²˜ì—ì„œ ì¡°ì‚¬ ì°¾ê¸°
                    mid = len(seg) // 2
                    split_patterns = ['ëŠ” ', 'ì€ ', 'ì´ ', 'ê°€ ', 'ë¥¼ ', 'ì„ ', 'ì—ì„œ ', 'ìœ¼ë¡œ ', 'ì— ', 'ë„ ', 'ë§Œ ']
                    best_split = -1
                    
                    for pattern in split_patterns:
                        idx = seg.find(pattern, mid - 15)
                        if idx != -1 and idx < mid + 15:
                            best_split = idx + len(pattern)
                            break
                    
                    if best_split > 0:
                        final_segments.append(seg[:best_split].strip())
                        final_segments.append(seg[best_split:].strip())
                    else:
                        final_segments.append(seg)
                else:
                    final_segments.append(seg)
            else:
                final_segments.append(seg)
        
        # ë¹ˆ ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
        final_segments = [s for s in final_segments if s.strip()]
        
        if not final_segments:
            final_segments = [script_text]
        
        clips = []
        time_per_segment = audio_duration / len(final_segments)
        
        # ìë§‰ì´ ìŒì„±ë³´ë‹¤ ì‚´ì§ ë¹¨ë¦¬ ë‚˜ì˜¤ë„ë¡ (ì‹±í¬ ë§ì¶”ê¸°)
        sync_offset = -0.2  # 0.3ì´ˆ ë¨¼ì € ë‚˜ì˜¤ê²Œ
        
        for i, segment in enumerate(final_segments):
            start_time = max(0, i * time_per_segment + sync_offset)
            duration = time_per_segment
            
            # PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„±
            subtitle_img = self._create_subtitle_image(segment)
            
            # ImageClipìœ¼ë¡œ ë³€í™˜
            clip = ImageClip(subtitle_img)
            clip = clip.with_duration(duration)
            clip = clip.with_start(start_time)
            # ìë§‰ ìœ„ì¹˜: ìƒë‹¨ì—ì„œ 1/3 ì§€ì 
            clip = clip.with_position(('center', int(self.height * 0.30)))
            
            clips.append(clip)
        
        return clips
    
    def create_thumbnail(self, text, output_path, background_img=None):
        """ì¸ë„¤ì¼ ì´ë¯¸ì§€ ìƒì„±"""
        if background_img:
            img = background_img.copy()
        else:
            img = Image.new('RGB', (self.width, self.height), color='#1a1a2e')
        
        draw = ImageDraw.Draw(img)
        
        # í•œê¸€ í°íŠ¸ ë¡œë“œ
        try:
            if self.font_path:
                font = ImageFont.truetype(self.font_path, 100)
            else:
                font = ImageFont.load_default()
        except:
            font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ
        max_width = self.width - 100
        lines = []
        current_line = ""
        
        for char in text:
            test_line = current_line + char
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = char
        if current_line:
            lines.append(current_line)
        
        # ì´ í…ìŠ¤íŠ¸ ë†’ì´ ê³„ì‚°
        line_height = 120
        total_height = len(lines) * line_height
        y_start = (self.height - total_height) // 2
        
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (self.width - text_width) // 2
            y = y_start + i * line_height
            
            # ê·¸ë¦¼ì
            draw.text((x+4, y+4), line, font=font, fill='black')
            draw.text((x+2, y+2), line, font=font, fill='#333333')
            # ë©”ì¸ í…ìŠ¤íŠ¸ (í˜•ê´‘ ë…¹ìƒ‰)
            draw.text((x, y), line, font=font, fill='#00ff88')
        
        img.save(output_path)
        print(f"âœ… ì¸ë„¤ì¼ ìƒì„±: {output_path}")
        return output_path
    
    def create_video(self, script_data, audio_path, output_path, sentence_timings=None):
        """ìµœì¢… ë¹„ë””ì˜¤ ìƒì„±"""
        try:
            print("ğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
            
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            audio = AudioFileClip(audio_path)
            duration = audio.duration
            
            # ëŒ€ë³¸ í…ìŠ¤íŠ¸ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            script_text = script_data.get('script', '')
            topic = script_data.get('topic', 'í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤')
            print(f"ğŸ“· ëŒ€ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë°°ê²½ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
            background_images = self.download_background_images(topic, count=5, script_text=script_text)
            
            # ë°°ê²½ ë¹„ë””ì˜¤ ìƒì„±
            background = self.create_background_video(background_images, duration)
            
            # ìë§‰ ìƒì„± (ìŒì„± íƒ€ì´ë° ê¸°ë°˜)
            subtitle_clips = self.create_subtitle_clips(script_data['script'], duration, sentence_timings=sentence_timings)
            
            # ëª¨ë“  í´ë¦½ í•©ì„±
            final_video = CompositeVideoClip(
                [background] + subtitle_clips,
                size=(self.width, self.height)
            ).with_duration(duration).with_audio(audio)
            
            # ë¹„ë””ì˜¤ ì €ì¥
            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True,
                preset='medium'
            )
            
            print(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    generator = VideoGenerator()
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
    test_script = {
        'script': 'ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ì˜ìƒì…ë‹ˆë‹¤. ìë§‰ì´ ì˜ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.',
        'thumbnail_text': 'í…ŒìŠ¤íŠ¸ ì˜ìƒ'
    }
    
    print("ë¹„ë””ì˜¤ ìƒì„±ê¸°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
