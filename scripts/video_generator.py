"""
ë¹„ë””ì˜¤ ìƒì„± ëª¨ë“ˆ
MoviePyë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±, ë°°ê²½, ìë§‰ì„ í•©ì„±í•˜ì—¬ ìµœì¢… ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
AI ì´ë¯¸ì§€ ìƒì„±: HuggingFace FLUX.1-schnell (1ìˆœìœ„) â†’ Together AI (2ìˆœìœ„) â†’ Pexels (3ìˆœìœ„)
"""

import json
import os
import requests
import sys
import time
import io
from contextlib import redirect_stdout
try:
    from moviepy import (
        ColorClip, AudioFileClip, CompositeVideoClip,
        TextClip, concatenate_videoclips, ImageClip, VideoClip
    )
except ImportError:
    print("âš ï¸ moviepy 2.x import ì‹¤íŒ¨, moviepy.editorì—ì„œ ì‹œë„...")
    from moviepy.editor import (  # type: ignore
        ColorClip, AudioFileClip, CompositeVideoClip,
        TextClip, concatenate_videoclips, ImageClip, VideoClip
    )
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import numpy as np


class VideoGenerator:
    def __init__(self, config_path="config/config.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        # ì‡¼ì¸  ë¹„ë””ì˜¤ ì„¤ì •
        shorts_config = self.config['video']['shorts']
        res = shorts_config['resolution'].split('x')
        self.width = int(res[0])
        self.height = int(res[1])
        self.fps = shorts_config['fps']
        self.bg_color = shorts_config['background_color']
        self.text_color = shorts_config['text_color']
        self.accent_color = shorts_config['accent_color']

        # AI ì´ë¯¸ì§€ ìƒì„± ì„¤ì •
        self.hf_token = self.config.get('huggingface_token', '')
        self.together_api_key = self.config.get('together_api_key', '')
        self.pexels_api_key = self.config.get('pexels_api_key', '')

        # í•œê¸€ í°íŠ¸ ì°¾ê¸°
        self.font_path = self._find_korean_font()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # AI ì´ë¯¸ì§€ ìƒì„± (3-tier í´ë°±)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def generate_ai_image_huggingface(self, prompt, retry_count=2):
        """HuggingFace FLUX.1-schnellë¡œ ì´ë¯¸ì§€ ìƒì„± (9:16 ì„¸ë¡œ)"""
        if not self.hf_token:
            return None

        url = "https://router.huggingface.co/hf-inference/models/black-forest-labs/FLUX.1-schnell"
        headers = {
            "Authorization": f"Bearer {self.hf_token}",
            "Content-Type": "application/json",
        }
        # 9:16 ë¹„ìœ¨ â†’ 768x1344
        payload = {
            "inputs": prompt,
            "parameters": {"width": 768, "height": 1344},
        }

        for attempt in range(retry_count):
            try:
                resp = requests.post(url, headers=headers, json=payload, timeout=60)
                if resp.status_code == 200 and resp.headers.get('content-type', '').startswith('image'):
                    img = Image.open(io.BytesIO(resp.content))
                    if img.size[0] > 100:
                        return img
                print(f"   âš ï¸ HF ì‘ë‹µ ì½”ë“œ {resp.status_code}, ì¬ì‹œë„ {attempt+1}/{retry_count}")
                time.sleep(3)
            except Exception as e:
                print(f"   âš ï¸ HF ì˜¤ë¥˜: {str(e)[:80]}, ì¬ì‹œë„ {attempt+1}/{retry_count}")
                time.sleep(3)
        return None

    def generate_ai_image_together(self, prompt, retry_count=2):
        """Together AI FLUX.1-schnellë¡œ ì´ë¯¸ì§€ ìƒì„± (9:16 ì„¸ë¡œ)"""
        if not self.together_api_key:
            return None

        url = "https://api.together.xyz/v1/images/generations"
        headers = {
            "Authorization": f"Bearer {self.together_api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": "black-forest-labs/FLUX.1-schnell-Free",
            "prompt": prompt,
            "width": 768,
            "height": 1344,
            "n": 1,
        }

        for attempt in range(retry_count):
            try:
                resp = requests.post(url, headers=headers, json=payload, timeout=60)
                if resp.status_code == 200:
                    data = resp.json()
                    img_data = data.get('data', [{}])[0]
                    if 'b64_json' in img_data:
                        import base64
                        img_bytes = base64.b64decode(img_data['b64_json'])
                        img = Image.open(io.BytesIO(img_bytes))
                        return img
                    elif 'url' in img_data:
                        img_resp = requests.get(img_data['url'], timeout=30)
                        if img_resp.status_code == 200:
                            img = Image.open(io.BytesIO(img_resp.content))
                            return img
                print(f"   âš ï¸ Together ì‘ë‹µ ì½”ë“œ {resp.status_code}, ì¬ì‹œë„ {attempt+1}/{retry_count}")
                time.sleep(3)
            except Exception as e:
                print(f"   âš ï¸ Together ì˜¤ë¥˜: {str(e)[:80]}, ì¬ì‹œë„ {attempt+1}/{retry_count}")
                time.sleep(3)
        return None

    def generate_ai_image(self, prompt, section_name="image"):
        """3-tier í´ë°±: HuggingFace â†’ Together AI â†’ Pexels"""
        # í”„ë¡¬í”„íŠ¸ì—ì„œ --ar 9:16 ë“± ì œê±° (APIëŠ” width/height íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        import re
        clean_prompt = re.sub(r'--\w+\s+\S+', '', prompt).strip()

        # 1ì°¨: HuggingFace FLUX.1-schnell
        print(f"   ğŸ¨ [{section_name}] HuggingFace ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        img = self.generate_ai_image_huggingface(clean_prompt)
        if img:
            print(f"   âœ… [{section_name}] HuggingFace ì„±ê³µ")
            return img

        # 2ì°¨: Together AI
        if self.together_api_key:
            print(f"   ğŸ¨ [{section_name}] Together AI í´ë°±...")
            img = self.generate_ai_image_together(clean_prompt)
            if img:
                print(f"   âœ… [{section_name}] Together AI ì„±ê³µ")
                return img

        # 3ì°¨: Pexels í‚¤ì›Œë“œ ê²€ìƒ‰
        print(f"   ğŸ“· [{section_name}] Pexels í´ë°±...")
        # í”„ë¡¬í”„íŠ¸ì—ì„œ ì˜ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = ' '.join(clean_prompt.split()[:5])
        pexels_images = self.download_background_images(keywords, count=1, script_text="")
        if pexels_images:
            print(f"   âœ… [{section_name}] Pexels ì„±ê³µ")
            return pexels_images[0]

        # ìµœì¢… í´ë°±: ê·¸ë¼ë””ì–¸íŠ¸
        print(f"   ğŸ¨ [{section_name}] ê·¸ë¼ë””ì–¸íŠ¸ í´ë°±")
        return self._create_gradient_image()

    def generate_ai_background_images(self, script_data, use_ai=True):
        """script_dataì˜ image_promptsë¥¼ ì‚¬ìš©í•´ 5ê°œ AI ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±"""
        if not use_ai:
            print("â„¹ï¸ AI ì´ë¯¸ì§€ ìƒì„± ë¹„í™œì„±í™”, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            return None

        image_prompts = script_data.get('image_prompts', [])
        if not image_prompts or len(image_prompts) < 5:
            print("âš ï¸ image_promptsê°€ 5ê°œ ë¯¸ë§Œ, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            return None

        try:
            print("ğŸ¨ AI ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (5ì¥)...")
            section_names = ["intro", "section1", "section2", "section3", "outro"]
            ai_images = []

            for i, (section, prompt) in enumerate(zip(section_names, image_prompts)):
                img = self.generate_ai_image(prompt, section_name=section)
                img = self._resize_and_crop(img)
                ai_images.append((section, img))
                # API ì†ë„ ì œí•œ ë°©ì§€ (ë§ˆì§€ë§‰ ì´ë¯¸ì§€ í›„ì—ëŠ” ëŒ€ê¸° ë¶ˆí•„ìš”)
                if i < 4:
                    time.sleep(1.5)

            print(f"âœ… ì´ {len(ai_images)}ê°œ AI ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            return ai_images

        except Exception as e:
            print(f"âŒ AI ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _find_korean_font(self):
        """ì‹œìŠ¤í…œì—ì„œ í•œê¸€ í°íŠ¸ ì°¾ê¸° (GitHub Actions ì§€ì›)"""
        # macOS í°íŠ¸ ê²½ë¡œë“¤
        font_paths = [
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/System/Library/Fonts/Supplemental/AppleGothic.ttf",
            "/Library/Fonts/AppleGothic.ttf",
            "/System/Library/Fonts/Helvetica.ttc",
            # Linux í°íŠ¸ ê²½ë¡œë“¤ (GitHub Actions)
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc",
            "/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf",
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            # ì¶”ê°€ Linux ê²½ë¡œ
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
        ]
        
        for path in font_paths:
            if os.path.exists(path):
                print(f"âœ… í•œê¸€ í°íŠ¸ ë°œê²¬: {path}")
                return path
        
        print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        return None
    
    def extract_keywords_from_script(self, script_text):
        """ëŒ€ë³¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ - ë‹¤ì–‘ì„± ì¦ê°€"""
        import re
        import random
        
        # í•œê¸€-ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘ (ê° í‚¤ì›Œë“œë³„ë¡œ ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ ì˜µì…˜)
        keyword_map = {
            # ê¸ˆìœµ/ì¬í…Œí¬ (ë‹¤ì–‘í•œ ì¿¼ë¦¬)
            "ëˆ": ["money finance", "cash wealth", "coins gold", "financial success"],
            "ì£¼ì‹": ["stock market", "trading chart", "investment growth", "financial data"],
            "ì•”í˜¸": ["cryptocurrency", "bitcoin blockchain", "digital currency"],
            "íˆ¬ì": ["investment portfolio", "business growth", "wealth building"],
            "ë¶€ë™ì‚°": ["real estate", "house property", "building architecture"],
            "ì´ì§": ["career change", "job interview", "business opportunity"],
            "ì ˆì•½": ["saving money", "budgeting finance", "piggy bank"],
            "ê¸ˆìœµ": ["banking finance", "economy growth", "financial planning"],
            
            # ì‹¬ë¦¬/ì„±ê³µ
            "ì‹¬ë¦¬": ["psychology mind", "brain thinking", "mental health"],
            "ì„±ê³µ": ["success winner", "achievement trophy", "business growth"],
            "ìì¡´ê°": ["confidence self", "empowerment motivation", "personal growth"],
            "ê´€ê³„": ["relationship people", "friendship together", "communication"],
            "ìŠ¤íŠ¸ë ˆìŠ¤": ["stress relief", "meditation peace", "relaxation calm"],
            "ì§‘ì¤‘": ["focus concentration", "meditation brain", "mindfulness"],
            "ìˆ˜ë©´": ["sleep rest", "bedroom night", "peaceful calm"],
            "ìŠµê´€": ["habit routine", "lifestyle healthy", "self improvement"],
            
            # ë·°í‹°/ê±´ê°•
            "ì–¼êµ´": ["face beauty", "skin care", "skincare routine"],
            "í”¼ë¶€": ["skin dermatology", "beauty cosmetics", "skincare"],
            "í—¬ìŠ¤": ["gym fitness", "exercise workout", "weight training"],
            "ê±´ê°•": ["health wellness", "nutrition healthy", "fitness lifestyle"],
            "ì‚´": ["weight loss", "diet healthy", "body fitness"],
            "ì—°ì˜ˆì¸": ["celebrity fame", "entertainment fashion", "glamour"],
            
            # ì»¤ë¦¬ì–´/í•™ìŠµ
            "ìœ íŠœë¸Œ": ["youtube content", "video production", "streaming media"],
            "ì•Œê³ ë¦¬ì¦˜": ["data algorithm", "artificial intelligence", "technology"],
            "ì§ì—…": ["career profession", "job workplace", "business"],
            "ë©´ì ‘": ["job interview", "business meeting", "interview"],
            "ì»¤ë¦¬ì–´": ["career growth", "professional development", "business"],
            "ì…ì‹œ": ["graduation school", "education campus", "university"],
            "ê³µë¬´ì›": ["government office", "civil service", "administration"],
            "ì˜ì–´": ["english language", "learning education", "language study"],
            
            # ê³¼í•™/ê¸°ìˆ 
            "ë‡Œ": ["brain neuroscience", "thinking intelligence", "mind science"],
            "ìš°ì£¼": ["space galaxy", "universe stars", "astronomy cosmos"],
            "í–‰ì„±": ["planet solar", "space universe", "astronomy"],
            "ë¸”ë™í™€": ["black hole space", "universe physics", "astronomy"],
            "íƒœì–‘": ["sun solar", "star bright", "astronomy"],
            "ë‹¬": ["moon lunar", "night sky", "space"],
            "ë³„": ["stars night", "constellation sky", "astronomy"],
            "ê³¼í•™": ["science laboratory", "research experiment", "technology"],
            "ì‹¤í—˜": ["experiment laboratory", "science research", "chemical"],
            "DNA": ["DNA genetics", "biology science", "microscope"],
            "ì„¸í¬": ["cell biology", "microscope science", "medical"],
            "ì›ì": ["atom physics", "molecule science", "quantum"],
            "ì—ë„ˆì§€": ["energy power", "electricity", "solar power"],
            "ì „ê¸°": ["electricity lightning", "power energy", "electrical"],
            "ë¡œë´‡": ["robot technology", "artificial intelligence", "automation"],
            "ì¸ê³µì§€ëŠ¥": ["artificial intelligence AI", "technology future", "robot"],
            "ì»´í“¨í„°": ["computer technology", "digital gadget", "electronics"],
            
            # ìì—°/ë™ë¬¼
            "ë°”ë‹¤": ["ocean underwater", "sea beach", "marine life"],
            "ì‚°": ["mountain nature", "landscape hiking", "wilderness"],
            "ìˆ²": ["forest trees", "nature woodland", "green landscape"],
            "ë™ë¬¼": ["animals wildlife", "nature fauna", "wildlife photography"],
            "ìƒˆ": ["birds flying", "wildlife nature", "bird photography"],
            "ë¬¼ê³ ê¸°": ["fish underwater", "aquatic marine", "ocean life"],
            "ê³ ë˜": ["whale ocean", "marine mammal", "underwater"],
            "ìƒì–´": ["shark ocean", "marine predator", "underwater"],
            "ì‚¬ì": ["lion wildlife", "safari animals", "wildlife africa"],
            "í˜¸ë‘ì´": ["tiger wildlife", "nature stripes", "big cats"],
            "ê³µë£¡": ["dinosaur prehistoric", "extinct animals", "fossil"],
            "ê³¤ì¶©": ["insects macro", "nature detail", "close up"],
            "ê½ƒ": ["flowers nature", "garden bloom", "colorful plants"],
            "ë‚˜ë¬´": ["trees forest", "nature leaves", "woodland"],
            
            # ì¸ì²´/ê±´ê°•
            "ì‹¬ì¥": ["heart medical", "cardiac health", "anatomy"],
            "ëˆˆ": ["eye vision", "sight optical", "eyeball"],
            "ê·€": ["ear hearing", "audio sound", "auditory"],
            "í”¼": ["blood medical", "vein anatomy", "healthcare"],
            "ê·¼ìœ¡": ["muscle fitness", "body workout", "exercise"],
            "ë¼ˆ": ["skeleton bones", "anatomy structure", "medical"],
            "ì¸ì²´": ["human body", "anatomy medical", "health"],
            
            # ì—­ì‚¬/ë¬¸í™”
            "ì—­ì‚¬": ["history ancient", "civilization culture", "historical"],
            "ì „ìŸ": ["war battle", "history conflict", "military"],
            "ì™•": ["king royal", "castle monarchy", "palace"],
            "í”¼ë¼ë¯¸ë“œ": ["pyramid egypt", "ancient architecture", "monument"],
            "ë¡œë§ˆ": ["rome ancient", "roman empire", "ancient civilization"],
            "ê·¸ë¦¬ìŠ¤": ["greece ancient", "greek temple", "antique"],
            "ì¤‘ì„¸": ["medieval castle", "knight history", "ancient times"],
            "ë¬¸ëª…": ["civilization ancient", "culture history", "society"],
            
            # ì„¸ê³„/ì§€ë¦¬
            "ì„¸ê³„": ["world globe", "earth travel", "international"],
            "ì§€êµ¬": ["earth planet", "world geography", "globe"],
            "ë‚˜ë¼": ["countries travel", "flags world", "international"],
            "ë„ì‹œ": ["city skyline", "urban landscape", "metropolis"],
            "ì‚¬ë§‰": ["desert landscape", "sand nature", "arid"],
            "ë¶ê·¹": ["arctic ice", "polar region", "snow"],
            "í™”ì‚°": ["volcano lava", "eruption nature", "geological"],
            "ì§€ì§„": ["earthquake disaster", "seismic", "natural disaster"],
            
            # ê°ì •/ê¸°íƒ€
            "ê°ì •": ["emotions feeling", "expression face", "psychology"],
            "ê¸°ì–µ": ["memory brain", "remembering thought", "mind"],
            "ê¿ˆ": ["dream sleep", "nighttime rest", "subconscious"],
            "í–‰ë³µ": ["happiness joy", "smile success", "celebration"],
            "ê³µí¬": ["fear horror", "dark scary", "thriller"],
            "ì‚¬ë‘": ["love romance", "heart relationship", "passion"],
            "ê¸°ë¡": ["record achievement", "trophy winner", "success"],
            "ìˆ«ì": ["numbers data", "statistics chart", "mathematics"],
        }
        
        # ëŒ€ë³¸ì—ì„œ ë§¤ì¹­ë˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
        found_keywords = []
        for kr, queries in keyword_map.items():
            if kr in script_text:
                # ê° í‚¤ì›Œë“œë§ˆë‹¤ ì—¬ëŸ¬ ì¿¼ë¦¬ ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒ
                if isinstance(queries, list):
                    found_keywords.append(random.choice(queries))
                else:
                    found_keywords.append(queries)
        
        # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë‹¤ì–‘í•œ ê¸°ë³¸ê°’ ì¤‘ ì„ íƒ
        if not found_keywords:
            default_queries = [
                "abstract dark background",
                "cinematic lighting", 
                "dramatic background",
                "modern minimal",
                "professional wallpaper",
                "inspirational poster",
                "creative design",
                "geometric pattern"
            ]
            found_keywords = [random.choice(default_queries)]
        
        return found_keywords

    def download_background_images(self, keywords, count=3, script_text=""):
        """Pexels APIë¡œ ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë‹¤ì–‘ì„± ì¦ê°€)"""
        import random
        
        images = []
        pexels_api_key = self.config.get('pexels_api_key', '')
        
        try:
            # ëŒ€ë³¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼)
            if script_text:
                search_queries = self.extract_keywords_from_script(script_text)
            else:
                # í† í”½ ê¸°ë°˜ í´ë°± (ê¸°ì¡´ í˜¸í™˜ì„±)
                keyword_map = {
                    "ëˆ": ["money finance", "wealth"],
                    "ì£¼ì‹": ["stock market", "trading"],
                    "ì‹¬ë¦¬": ["psychology mind", "brain thinking"],
                    "ê±´ê°•": ["health wellness", "fitness"],
                    "ì—­ì‚¬": ["history ancient", "civilization"],
                    "ìš°ì£¼": ["space galaxy", "astronomy"],
                    "ê¸°ìˆ ": ["technology future", "innovation"],
                }
                search_queries = ["abstract dark background"]
                for kr, qs in keyword_map.items():
                    if kr in keywords:
                        search_queries = qs if isinstance(qs, list) else [qs]
                        break
            
            headers = {"Authorization": pexels_api_key}
            
            # ëœë¤ í˜ì´ì§€ ì˜¤í”„ì…‹ìœ¼ë¡œ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            page_offset = random.randint(1, 10)
            
            # ê° í‚¤ì›Œë“œë³„ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰
            for query in search_queries[:8]:  # ìµœëŒ€ 8ê°œ í‚¤ì›Œë“œ
                if len(images) >= count:
                    break
                
                try:
                    # ëœë¤ í˜ì´ì§€ ì‚¬ìš©ìœ¼ë¡œ ë§¤ë²ˆ ë‹¤ë¥¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
                    page = page_offset + random.randint(0, 5)
                    per_page = max(5, count - len(images) + 2)
                    
                    url = f"https://api.pexels.com/v1/search?query={query}&per_page={per_page}&page={page}&orientation=portrait"
                    response = requests.get(url, headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        photos = data.get('photos', [])
                        
                        # ì—¬ëŸ¬ ì‚¬ì§„ ì¤‘ì—ì„œ ëœë¤ ì„ íƒìœ¼ë¡œ ë‹¤ì–‘ì„± ì¦ê°€
                        if len(photos) > 0:
                            random.shuffle(photos)
                            for photo in photos:
                                if len(images) >= count:
                                    break
                                try:
                                    img_url = photo['src']['large2x']
                                    img_response = requests.get(img_url, timeout=10)
                                    if img_response.status_code == 200:
                                        from io import BytesIO
                                        img = Image.open(BytesIO(img_response.content))
                                        img = self._resize_and_crop(img)
                                        images.append(img)
                                        print(f"âœ… ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ({query}): {len(images)}/{count}")
                                except:
                                    continue
                except Exception as e:
                    print(f"âš ï¸  ì¿¼ë¦¬ ì‹¤íŒ¨ ({query}): {e}")
                    continue
            
        except Exception as e:
            print(f"âš ï¸ ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ì´ë¯¸ì§€ ë¶€ì¡± ì‹œ - ë‹¤ì–‘í•œ í´ë°± ì¿¼ë¦¬ë¡œ ì¶”ê°€ ê²€ìƒ‰
        if len(images) < count:
            fallback_queries = [
                "dark abstract modern",
                "night sky stars",
                "nature landscape scenic",
                "cinematic dramatic lighting",
                "urban city modern",
                "technology digital future",
                "professional business",
                "creative artistic",
                "minimalist design",
                "colorful vibrant",
                "moody atmospheric",
                "energy power",
                "success achievement",
                "growth development",
                "motion dynamic",
                "bright sunny"
            ]
            
            # ëœë¤ìœ¼ë¡œ ì„ì–´ì„œ ìˆœíšŒ
            random.shuffle(fallback_queries)
            
            for query in fallback_queries:
                if len(images) >= count:
                    break
                
                try:
                    # ë§¤ë²ˆ ë‹¤ë¥¸ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    page = random.randint(1, 15)
                    print(f"ğŸ“· ì¶”ê°€ ë°°ê²½ ê²€ìƒ‰ ({query}) - page {page}...")
                    
                    url = f"https://api.pexels.com/v1/search?query={query}&per_page=5&page={page}&orientation=portrait"
                    response = requests.get(url, headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        photos = data.get('photos', [])
                        
                        if len(photos) > 0:
                            random.shuffle(photos)
                            for photo in photos:
                                if len(images) >= count:
                                    break
                                try:
                                    img_url = photo['src']['large2x']
                                    img_response = requests.get(img_url, timeout=10)
                                    if img_response.status_code == 200:
                                        from io import BytesIO
                                        img = Image.open(BytesIO(img_response.content))
                                        img = self._resize_and_crop(img)
                                        images.append(img)
                                        print(f"âœ… ì¶”ê°€ ë°°ê²½: {len(images)}/{count}")
                                except:
                                    continue
                except:
                    continue
        
        # ê·¸ë˜ë„ ë¶€ì¡±í•˜ë©´ ì¸ê¸° ì´ë¯¸ì§€ì—ì„œ ì¶”ê°€ (ë‹¤ì–‘í•œ í˜ì´ì§€)
        if len(images) < count:
            try:
                print("ğŸ“· ì¸ê¸° ì´ë¯¸ì§€ì—ì„œ ì¶”ê°€ ê²€ìƒ‰...")
                page = random.randint(1, 50)
                url = f"https://api.pexels.com/v1/curated?per_page={count - len(images) + 3}&page={page}&orientation=portrait"
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    photos = data.get('photos', [])
                    
                    if len(photos) > 0:
                        random.shuffle(photos)
                        for photo in photos:
                            if len(images) >= count:
                                break
                            try:
                                img_url = photo['src']['large2x']
                                img_response = requests.get(img_url, timeout=10)
                                if img_response.status_code == 200:
                                    from io import BytesIO
                                    img = Image.open(BytesIO(img_response.content))
                                    img = self._resize_and_crop(img)
                                    images.append(img)
                                    print(f"âœ… ì¸ê¸° ì´ë¯¸ì§€ ì¶”ê°€: {len(images)}/{count}")
                            except:
                                continue
            except:
                pass
        
        return images
    
    def _resize_and_crop(self, img):
        """ì´ë¯¸ì§€ë¥¼ ì„¸ë¡œ í˜•ì‹ìœ¼ë¡œ í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ"""
        target_ratio = self.height / self.width
        img_ratio = img.height / img.width
        
        if img_ratio > target_ratio:
            # ì´ë¯¸ì§€ê°€ ë” ì„¸ë¡œë¡œ ê¹€ - ìœ„ì•„ë˜ ìë¥´ê¸°
            new_height = int(img.width * target_ratio)
            top = (img.height - new_height) // 2
            img = img.crop((0, top, img.width, top + new_height))
        else:
            # ì´ë¯¸ì§€ê°€ ë” ê°€ë¡œë¡œ ê¹€ - ì¢Œìš° ìë¥´ê¸°
            new_width = int(img.height / target_ratio)
            left = (img.width - new_width) // 2
            img = img.crop((left, 0, left + new_width, img.height))
        
        img = img.resize((self.width, self.height), Image.LANCZOS)
        
        # ì–´ë‘¡ê²Œ ì²˜ë¦¬ (ìë§‰ì´ ì˜ ë³´ì´ë„ë¡)
        enhancer = Image.new('RGBA', img.size, (0, 0, 0, 150))
        img = img.convert('RGBA')
        img = Image.alpha_composite(img, enhancer)
        
        return img.convert('RGB')
    
    def _create_gradient_image(self):
        """ê·¸ë¼ë””ì–¸íŠ¸ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±"""
        img = Image.new('RGB', (self.width, self.height))
        draw = ImageDraw.Draw(img)
        
        # ê·¸ë¼ë””ì–¸íŠ¸ ìƒ‰ìƒ
        colors = [
            ((26, 26, 46), (46, 46, 86)),
            ((20, 30, 48), (36, 59, 85)),
            ((15, 32, 39), (32, 58, 67)),
        ]
        
        import random
        c1, c2 = random.choice(colors)
        
        for i in range(self.height):
            ratio = i / self.height
            r = int(c1[0] + (c2[0] - c1[0]) * ratio)
            g = int(c1[1] + (c2[1] - c1[1]) * ratio)
            b = int(c1[2] + (c2[2] - c1[2]) * ratio)
            draw.line([(0, i), (self.width, i)], fill=(r, g, b))
        
        return img

    def create_background_video(self, images, duration, section_times=None):
        """ë°°ê²½ ì´ë¯¸ì§€ë“¤ë¡œ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± (ì„¹ì…˜ íƒ€ì´ë° ë™ê¸°í™”)"""
        if not images:
            return ColorClip(
                size=(self.width, self.height),
                color=(26, 26, 46),
                duration=duration
            ).with_fps(self.fps)
        
        clips = []
        
        # ì„¹ì…˜ íƒ€ì´ë°ì´ ìˆìœ¼ë©´ ì„¹ì…˜ë³„ë¡œ ì´ë¯¸ì§€ ë°°ì¹˜
        if section_times and len(section_times) == len(images) + 1:
            print(f"   ğŸ–¼ï¸  ì„¹ì…˜ íƒ€ì´ë° ê¸°ë°˜ ì´ë¯¸ì§€ ë°°ì¹˜ ({len(images)}ì¥)")
            for i, img in enumerate(images):
                start = section_times[i]
                end = section_times[i + 1]
                dur = max(0.1, end - start)  # ìµœì†Œ 0.1ì´ˆ
                
                img_array = np.array(img)
                clip = ImageClip(img_array).with_duration(dur)
                clip = clip.with_start(start)
                clips.append(clip)
                print(f"      ì´ë¯¸ì§€ {i+1}: {start:.1f}s ~ {end:.1f}s ({dur:.1f}s)")
        else:
            # ê· ë“± ë¶„ë°° (í´ë°±)
            time_per_image = duration / len(images)
            for i, img in enumerate(images):
                img_array = np.array(img)
                clip = ImageClip(img_array).with_duration(time_per_image)
                clip = clip.with_start(i * time_per_image)
                clips.append(clip)
        
        return CompositeVideoClip(clips, size=(self.width, self.height)).with_fps(self.fps)
    
    def _create_subtitle_image(self, text, font_size=80, text_color=(255, 255, 255, 255), is_bold=False):
        """PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„± (í•œê¸€ ì§€ì›, ë‹¨ì–´ ë‹¨ìœ„ ì¤„ë°”ê¿ˆ, ìƒ‰ìƒ/ë³¼ë“œ ì§€ì›)"""
        # ì¼ë‹¨ ì„ì‹œ ì´ë¯¸ì§€ë¡œ í…ìŠ¤íŠ¸ í¬ê¸° ì¸¡ì •
        temp_img = Image.new('RGBA', (self.width, 400), (0, 0, 0, 0))
        temp_draw = ImageDraw.Draw(temp_img)
        
        # í°íŠ¸ ë¡œë“œ (GitHub Actions í˜¸í™˜)
        font = None
        try:
            if self.font_path:
                font = ImageFont.truetype(self.font_path, font_size)
            else:
                # GitHub Actionsì—ì„œ í´ë°±
                fallback_fonts = [
                    "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
                    "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
                    "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                ]
                for font_path in fallback_fonts:
                    if os.path.exists(font_path):
                        try:
                            font = ImageFont.truetype(font_path, font_size)
                            break
                        except:
                            continue
        except:
            pass
        
        if not font:
            font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ - ë‹¨ì–´ ë‹¨ìœ„ë¡œ ì¤„ë°”ê¿ˆ (ë¬¸ì ë‹¨ìœ„ ì•„ë‹˜)
        # ìµœëŒ€ 2ì¤„ì´ ê¸°ë³¸ì´ì§€ë§Œ, ë¬¸ì¥ì´ ê¸¸ë©´ 3ì¤„ ì´ìƒê¹Œì§€ í—ˆìš© (ë¬¸ì¥ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡)
        max_width = self.width - 120
        lines = []
        current_line = ""
        
        # ê³µë°± ë‹¨ìœ„ë¡œ ë‹¨ì–´ ë¶„í•  (ë„ì–´ì“°ê¸° ê¸°ì¤€)
        words = text.split(' ')
        
        for word in words:
            # í˜„ì¬ ì¤„ì— ë‹¨ì–´ ì¶”ê°€ ì‹œë„
            test_line = current_line + (' ' if current_line else '') + word
            bbox = temp_draw.textbbox((0, 0), test_line, font=font)
            
            if bbox[2] - bbox[0] <= max_width:
                # ë‹¨ì–´ê°€ ë“¤ì–´ê°
                current_line = test_line
            else:
                # ë‹¨ì–´ê°€ ë“¤ì–´ê°€ì§€ ì•ŠìŒ
                if current_line:
                    # í˜„ì¬ ì¤„ ì €ì¥í•˜ê³  ìƒˆë¡œìš´ ì¤„ì— ë‹¨ì–´ ì¶”ê°€
                    lines.append(current_line)
                    current_line = word
                else:
                    # í˜„ì¬ ì¤„ì´ ë¹„ì–´ìˆëŠ”ë°ë„ ë‹¨ì–´ê°€ ë„ˆë¬´ ê¸´ ê²½ìš°
                    # ì–´ì©” ìˆ˜ ì—†ì´ ë‹¨ì–´ ìì²´ë¥¼ ì¤„ë¡œ ì¶”ê°€
                    lines.append(word)
                    current_line = ""
        
        if current_line:
            lines.append(current_line)
        
        # í•„ìš”í•œ ì´ë¯¸ì§€ ë†’ì´ ê³„ì‚° (ì¤„ ìˆ˜ì— ë”°ë¼ ë™ì  ì¡°ì •)
        line_height = font_size + 25
        padding = 20
        text_bg_height = len(lines) * line_height + (padding * 2)
        img_height = text_bg_height + 40  # ìœ„ì•„ë˜ ì—¬ìœ 
        
        # ìµœì¢… ì´ë¯¸ì§€ ìƒì„± (ë†’ì´ëŠ” ë™ì )
        img = Image.new('RGBA', (self.width, img_height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        
        # ê²€ì •ìƒ‰ ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì‹œì¸ì„± ê°œì„ )
        # í…ìŠ¤íŠ¸ ì˜ì—­ì„ í¬í•¨í•˜ëŠ” ê²€ì •ìƒ‰ ë°•ìŠ¤
        box_top = 20
        box_bottom = box_top + text_bg_height
        box_left = 40
        box_right = self.width - 40
        
        # ê²€ì •ìƒ‰ ë°•ìŠ¤ (ì•½ê°„ì˜ íˆ¬ëª…ë„ í¬í•¨)
        box_img = Image.new('RGBA', (self.width, img_height), (0, 0, 0, 0))
        box_draw = ImageDraw.Draw(box_img)
        box_draw.rectangle(
            [(box_left, box_top), (box_right, box_bottom)],
            fill=(0, 0, 0, 220)  # ê²€ì •ìƒ‰, ì•½ê°„ íˆ¬ëª…
        )
        # í…Œë‘ë¦¬ (ì§„í•œ ê²€ì •)
        box_draw.rectangle(
            [(box_left, box_top), (box_right, box_bottom)],
            outline=(0, 0, 0, 255),
            width=3
        )
        
        # ë°•ìŠ¤ ì´ë¯¸ì§€ í•©ì„±
        img = Image.alpha_composite(img, box_img)
        draw = ImageDraw.Draw(img)
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ê·¸ë¦¼ì + ì™¸ê³½ì„  + í°ìƒ‰ ë³¸ë¬¸)
        y_offset = box_top + padding
        
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (self.width - text_width) // 2
            
            # ê·¸ë¦¼ì íš¨ê³¼
            for offset in [(4, 4), (3, 3), (2, 2)]:
                draw.text((x + offset[0], y_offset + offset[1]), line, font=font, fill=(0, 0, 0, 200))
            
            # ì™¸ê³½ì„ 
            for dx in [-2, -1, 0, 1, 2]:
                for dy in [-2, -1, 0, 1, 2]:
                    if dx != 0 or dy != 0:
                        draw.text((x + dx, y_offset + dy), line, font=font, fill=(0, 0, 0, 255))
            
            # ë³¸ë¬¸ í…ìŠ¤íŠ¸ (ì§€ì • ìƒ‰ìƒ)
            draw.text((x, y_offset), line, font=font, fill=text_color)
            if is_bold:
                # Faux-bold: 1px, 2px ì˜¤í”„ì…‹ìœ¼ë¡œ ì¤‘ë³µ ê·¸ë¦¬ê¸°
                draw.text((x + 1, y_offset), line, font=font, fill=text_color)
                draw.text((x + 2, y_offset), line, font=font, fill=text_color)
            y_offset += line_height
        
        return np.array(img)
    
    def create_subtitle_clips(self, script_text, audio_duration, sentence_timings=None):
        """ìë§‰ í´ë¦½ ìƒì„± (PIL ê¸°ë°˜, í•œê¸€ ì§€ì›, ìŒì„± íƒ€ì´ë° ê¸°ë°˜)"""
        import re
        
        # ìŒì„± íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
        if sentence_timings and len(sentence_timings) > 0:
            print(f"   ğŸ“ ìŒì„± íƒ€ì´ë° ê¸°ë°˜ ìë§‰ ìƒì„± ({len(sentence_timings)}ê°œ ë¬¸ì¥)")
            clips = []
            
            # â”€â”€ 1ë‹¨ê³„: TTS íƒ€ì´ë°ì„ ê°œë³„ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬ â”€â”€
            # Edge TTS SentenceBoundaryê°€ "ì²«ì§¸, ~~~. ê·¸ë˜ì„œ~~~." ì„ í•˜ë‚˜ë¡œ ë¬¶ëŠ” ê²½ìš° ë¶„ë¦¬
            split_timings = []
            for i, timing in enumerate(sentence_timings):
                text = timing["text"].strip()
                start_time = timing["start"]
                if i < len(sentence_timings) - 1:
                    end_time = sentence_timings[i + 1]["start"]
                else:
                    end_time = audio_duration
                total_dur = end_time - start_time
                
                # ë¬¸ì¥ ë¶€í˜¸(. ! ?)ë¡œ ë¶„ë¦¬ ì‹œë„ (ë¶€í˜¸ í¬í•¨)
                sub_sents = re.split(r'(?<=[.!?])\s+', text)
                sub_sents = [s.strip() for s in sub_sents if s.strip()]
                
                if len(sub_sents) > 1:
                    # ê¸€ì ìˆ˜ ë¹„ë¡€ë¡œ ì‹œê°„ ë¶„ë°°
                    total_chars = sum(len(s) for s in sub_sents)
                    cur_start = start_time
                    for j, sub in enumerate(sub_sents):
                        ratio = len(sub) / total_chars if total_chars > 0 else 1.0 / len(sub_sents)
                        sub_dur = total_dur * ratio
                        split_timings.append({
                            "text": sub,
                            "start": cur_start,
                            "end": cur_start + sub_dur,
                            "original_index": i
                        })
                        cur_start += sub_dur
                else:
                    split_timings.append({
                        "text": text,
                        "start": start_time,
                        "end": end_time,
                        "original_index": i
                    })
            
            total_split = len(split_timings)
            print(f"   ğŸ“ ë¬¸ì¥ ë¶„ë¦¬ í›„ ìë§‰ {total_split}ê°œ")
            
            # â”€â”€ 2ë‹¨ê³„: ê° ë¶„ë¦¬ëœ ë¬¸ì¥ì— ìƒ‰ìƒ/ë³¼ë“œ ê²°ì • + í´ë¦½ ìƒì„± â”€â”€
            for idx, st in enumerate(split_timings):
                text = st["text"]
                start_time = st["start"]
                duration = st["end"] - st["start"]
                orig_i = st["original_index"]
                
                if duration < 0.05:
                    continue
                
                # ë¬¸ì¥ ìœ í˜•ì— ë”°ë¼ ìƒ‰ìƒ/ë³¼ë“œ ê²°ì •
                RED = (255, 0, 0, 255)
                WHITE = (255, 255, 255, 255)
                tc = WHITE
                bold = False
                
                if orig_i == 0 and idx == 0:  # ì¸íŠ¸ë¡œ (ì²« ë¬¸ì¥)
                    tc = RED
                elif re.search(r'\d+ê°€ì§€', text):  # Nê°€ì§€
                    tc = RED
                    bold = True
                elif re.match(r'^(ì²«ì§¸|ë‘˜ì§¸|ì…‹ì§¸)', text):  # ìˆœì„œ ë¬¸ì¥ (í•´ë‹¹ ë¬¸ì¥ë§Œ)
                    tc = RED
                elif orig_i == len(sentence_timings) - 1 and idx == total_split - 1:  # ì•„ì›ƒíŠ¸ë¡œ (ë§ˆì§€ë§‰)
                    tc = RED
                
                # PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„±
                subtitle_img = self._create_subtitle_image(text, text_color=tc, is_bold=bold)
                
                # ImageClipìœ¼ë¡œ ë³€í™˜
                clip = ImageClip(subtitle_img)
                clip = clip.with_duration(duration)
                clip = clip.with_start(start_time)
                clip = clip.with_position(('center', int(self.height * 0.25)))
                
                clips.append(clip)
            
            return clips
        
        # íƒ€ì´ë° ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ (ê· ë“± ë¶„ë°°)
        print("   ğŸ“ ê· ë“± ë¶„ë°° ë°©ì‹ ìë§‰ ìƒì„±")
        
        # ë¬¸ë§¥ìƒ ìì—°ìŠ¤ëŸ¬ìš´ ìœ„ì¹˜ì—ì„œ ìë§‰ ë¶„ë¦¬
        # 1. ë¨¼ì € ë¬¸ì¥ ë¶€í˜¸ë¡œ ë¶„ë¦¬
        # 2. ê¸´ ë¬¸ì¥ì€ ì¡°ì‚¬/ì–´ë¯¸ ìœ„ì¹˜ì—ì„œ ì¶”ê°€ ë¶„ë¦¬
        
        # ë¬¸ì¥ ë¶€í˜¸ë¡œ 1ì°¨ ë¶„ë¦¬ (ë¶€í˜¸ ìœ ì§€)
        raw_segments = re.split(r'([.!?]+\s*)', script_text)
        segments = []
        
        for i in range(0, len(raw_segments) - 1, 2):
            text = raw_segments[i]
            punct = raw_segments[i + 1] if i + 1 < len(raw_segments) else ""
            if text.strip():
                segments.append(text.strip() + punct.strip())
        
        # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
        if len(raw_segments) % 2 == 1 and raw_segments[-1].strip():
            segments.append(raw_segments[-1].strip())
        
        # ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ ì‰¼í‘œë‚˜ ìì—°ìŠ¤ëŸ¬ìš´ ìœ„ì¹˜ì—ì„œ ë¶„ë¦¬
        final_segments = []
        for seg in segments:
            if len(seg) > 35:  # 35ì ì´ìƒì´ë©´ ë¶„ë¦¬ ì‹œë„
                # ì‰¼í‘œë¡œ ë¶„ë¦¬
                if ',' in seg:
                    parts = seg.split(',')
                    for j, part in enumerate(parts):
                        part = part.strip()
                        if part:
                            if j < len(parts) - 1:
                                final_segments.append(part + ',')
                            else:
                                final_segments.append(part)
                # ì¡°ì‚¬ ìœ„ì¹˜ì—ì„œ ë¶„ë¦¬ (ëŠ”, ì€, ì´, ê°€, ë¥¼, ì„, ì—ì„œ, ìœ¼ë¡œ ë“±)
                elif len(seg) > 40:
                    # ì¤‘ê°„ ì§€ì  ê·¼ì²˜ì—ì„œ ì¡°ì‚¬ ì°¾ê¸°
                    mid = len(seg) // 2
                    split_patterns = ['ëŠ” ', 'ì€ ', 'ì´ ', 'ê°€ ', 'ë¥¼ ', 'ì„ ', 'ì—ì„œ ', 'ìœ¼ë¡œ ', 'ì— ', 'ë„ ', 'ë§Œ ']
                    best_split = -1
                    
                    for pattern in split_patterns:
                        idx = seg.find(pattern, mid - 15)
                        if idx != -1 and idx < mid + 15:
                            best_split = idx + len(pattern)
                            break
                    
                    if best_split > 0:
                        final_segments.append(seg[:best_split].strip())
                        final_segments.append(seg[best_split:].strip())
                    else:
                        final_segments.append(seg)
                else:
                    final_segments.append(seg)
            else:
                final_segments.append(seg)
        
        # ë¹ˆ ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
        final_segments = [s for s in final_segments if s.strip()]
        
        if not final_segments:
            final_segments = [script_text]
        
        clips = []
        time_per_segment = audio_duration / len(final_segments)
        
        # ìë§‰ì´ ìŒì„±ë³´ë‹¤ ì‚´ì§ ë¹¨ë¦¬ ë‚˜ì˜¤ë„ë¡ (ì‹±í¬ ë§ì¶”ê¸°)
        sync_offset = -0.2  # 0.3ì´ˆ ë¨¼ì € ë‚˜ì˜¤ê²Œ
        
        for i, segment in enumerate(final_segments):
            start_time = max(0, i * time_per_segment + sync_offset)
            duration = time_per_segment
            
            # PILë¡œ ìë§‰ ì´ë¯¸ì§€ ìƒì„±
            subtitle_img = self._create_subtitle_image(segment)
            
            # ImageClipìœ¼ë¡œ ë³€í™˜
            clip = ImageClip(subtitle_img)
            clip = clip.with_duration(duration)
            clip = clip.with_start(start_time)
            # ìë§‰ ìœ„ì¹˜: ìƒë‹¨ì—ì„œ 1/4 ì§€ì  (ë†’ì´ 25%)
            clip = clip.with_position(('center', int(self.height * 0.25)))
            
            clips.append(clip)
        
        return clips
    
    def create_thumbnail(self, text, output_path, background_img=None):
        """ì¸ë„¤ì¼ ì´ë¯¸ì§€ ìƒì„±"""
        if background_img:
            img = background_img.copy()
        else:
            img = Image.new('RGB', (self.width, self.height), color='#1a1a2e')
        
        draw = ImageDraw.Draw(img)
        
        # í•œê¸€ í°íŠ¸ ë¡œë“œ (GitHub Actions í˜¸í™˜)
        font = None
        try:
            if self.font_path:
                font = ImageFont.truetype(self.font_path, 100)
            else:
                # GitHub Actionsì—ì„œ í´ë°±
                fallback_fonts = [
                    "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
                    "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
                    "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                ]
                for font_path in fallback_fonts:
                    if os.path.exists(font_path):
                        try:
                            font = ImageFont.truetype(font_path, 100)
                            break
                        except:
                            continue
        except:
            pass
        
        if not font:
            font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ
        max_width = self.width - 100
        lines = []
        current_line = ""
        
        for char in text:
            test_line = current_line + char
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = char
        if current_line:
            lines.append(current_line)
        
        # ì´ í…ìŠ¤íŠ¸ ë†’ì´ ê³„ì‚°
        line_height = 120
        total_height = len(lines) * line_height
        y_start = (self.height - total_height) // 2
        
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (self.width - text_width) // 2
            y = y_start + i * line_height
            
            # ê·¸ë¦¼ì
            draw.text((x+4, y+4), line, font=font, fill='black')
            draw.text((x+2, y+2), line, font=font, fill='#333333')
            # ë©”ì¸ í…ìŠ¤íŠ¸ (í˜•ê´‘ ë…¹ìƒ‰)
            draw.text((x, y), line, font=font, fill='#00ff88')
        
        img.save(output_path)
        print(f"âœ… ì¸ë„¤ì¼ ìƒì„±: {output_path}")
        return output_path
    
    def get_thumbnail_path(self):
        """ë§ˆì§€ë§‰ create_video í˜¸ì¶œ ì‹œ ìƒì„±ëœ ì¸ë„¤ì¼ ê²½ë¡œ ë°˜í™˜"""
        return getattr(self, '_thumbnail_path', None)

    def _create_hook_thumbnail(self, pil_image, hook_text, output_path):
        """ì¸íŠ¸ë¡œ ë°°ê²½ ì´ë¯¸ì§€ + í›„í‚¹ ë¬¸ì¥ ì˜¤ë²„ë ˆì´ë¡œ ì¸ë„¤ì¼ ìƒì„± (ì‡¼ì¸  9:16)"""
        try:
            bg = pil_image.copy().convert('RGB')
            draw = ImageDraw.Draw(bg)

            font_size = 72
            font = None
            try:
                if self.font_path:
                    font = ImageFont.truetype(self.font_path, font_size)
            except:
                pass
            if not font:
                font = ImageFont.load_default()

            # ë‹¨ì–´ ë‹¨ìœ„ ì¤„ë°”ê¿ˆ
            max_width = self.width - 150
            lines = []
            current_line = ""
            for word in hook_text.split(' '):
                test_line = current_line + (' ' if current_line else '') + word
                bbox = draw.textbbox((0, 0), test_line, font=font)
                if bbox[2] - bbox[0] <= max_width:
                    current_line = test_line
                else:
                    if current_line:
                        lines.append(current_line)
                    current_line = word
            if current_line:
                lines.append(current_line)

            line_height = font_size + 25
            total_text_h = len(lines) * line_height
            y_start = int(self.height * 0.25)  # ìƒë‹¨ 1/4 ì§€ì  (ìë§‰ ìœ„ì¹˜)

            # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤
            pad = 25
            overlay = Image.new('RGBA', (self.width, self.height), (0, 0, 0, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            overlay_draw.rectangle(
                [(40, y_start - pad), (self.width - 40, y_start + total_text_h + pad)],
                fill=(0, 0, 0, 180)
            )
            bg = Image.alpha_composite(bg.convert('RGBA'), overlay).convert('RGB')
            draw = ImageDraw.Draw(bg)

            RED = (255, 0, 0)
            for idx, line in enumerate(lines):
                bbox = draw.textbbox((0, 0), line, font=font)
                tw = bbox[2] - bbox[0]
                x = (self.width - tw) // 2
                y = y_start + idx * line_height

                for ox, oy in [(4, 4), (3, 3), (2, 2)]:
                    draw.text((x + ox, y + oy), line, font=font, fill=(0, 0, 0))
                for dx in [-3, -2, -1, 0, 1, 2, 3]:
                    for dy in [-3, -2, -1, 0, 1, 2, 3]:
                        if dx != 0 or dy != 0:
                            draw.text((x + dx, y + dy), line, font=font, fill=(0, 0, 0))
                draw.text((x, y), line, font=font, fill=RED)
                draw.text((x + 1, y), line, font=font, fill=RED)
                draw.text((x + 2, y), line, font=font, fill=RED)

            bg.save(output_path, 'JPEG', quality=95)
            print(f"   âœ… ì‡¼ì¸  í›„í‚¹ ì¸ë„¤ì¼ ìƒì„±: {output_path}")
            return output_path
        except Exception as e:
            print(f"   âš ï¸ ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _detect_section_boundaries(self, sentence_timings, duration):
        """ë¬¸ì¥ íƒ€ì´ë°ì—ì„œ ì„¹ì…˜ ê²½ê³„ ì‹œê°„ ê°ì§€ (ì¸íŠ¸ë¡œ/ì²«ì§¸/ë‘˜ì§¸/ì…‹ì§¸/ì•„ì›ƒíŠ¸ë¡œ)"""
        import re
        if not sentence_timings or len(sentence_timings) == 0:
            return None
        
        # ì²«ì§¸/ë‘˜ì§¸/ì…‹ì§¸ ì‹œì‘ ì‹œê°„ ì°¾ê¸°
        ordinal_times = []
        for timing in sentence_timings:
            text = timing['text']
            if re.match(r'^(ì²«ì§¸|ë‘˜ì§¸|ì…‹ì§¸)', text):
                ordinal_times.append(timing['start'])
        
        if len(ordinal_times) < 3:
            print(f"   âš ï¸  ì„¹ì…˜ ê²½ê³„ ë¶€ì¡± ({len(ordinal_times)}ê°œ ë°œê²¬), ê· ë“± ë¶„ë°° ì‚¬ìš©")
            return None
        
        # ë§ˆì§€ë§‰ ë¬¸ì¥ = ì•„ì›ƒíŠ¸ë¡œ ì‹œì‘
        outro_start = sentence_timings[-1]['start']
        
        # ê²½ê³„: [0, ì²«ì§¸, ë‘˜ì§¸, ì…‹ì§¸, ì•„ì›ƒíŠ¸ë¡œ, ë]
        boundaries = [0] + ordinal_times[:3] + [outro_start, duration]
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        boundaries = sorted(list(set(boundaries)))
        
        if len(boundaries) != 6:
            print(f"   âš ï¸  ê²½ê³„ ìˆ˜ ë¶ˆì¼ì¹˜ ({len(boundaries)}ê°œ), ê· ë“± ë¶„ë°° ì‚¬ìš©")
            return None
        
        print(f"   ğŸ¯ ì„¹ì…˜ ê²½ê³„ ê°ì§€ ì™„ë£Œ:")
        sections = ["ì¸íŠ¸ë¡œ", "ì²«ì§¸", "ë‘˜ì§¸", "ì…‹ì§¸", "ì•„ì›ƒíŠ¸ë¡œ"]
        for i in range(5):
            print(f"      {sections[i]}: {boundaries[i]:.1f}s ~ {boundaries[i+1]:.1f}s")
        
        return boundaries
    
    def create_video(self, script_data, audio_path, output_path, sentence_timings=None, use_ai_background=True):
        """ìµœì¢… ë¹„ë””ì˜¤ ìƒì„± (AI ë°°ê²½ ì´ë¯¸ì§€ ì˜µì…˜, ì¸ë„¤ì¼ ìë™ ìƒì„±)"""
        self._thumbnail_path = None  # ì¸ë„¤ì¼ ê²½ë¡œ
        audio = None
        final_video = None
        try:
            print("ğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
            
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            audio = AudioFileClip(audio_path)
            duration = audio.duration
            
            # AI ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì‹œë„
            ai_images = None
            if use_ai_background:
                ai_images = self.generate_ai_background_images(script_data, use_ai=True)
            
            # AI ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            if not ai_images:
                print("ğŸ“· ê¸°ì¡´ ë°©ì‹: ëŒ€ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë°°ê²½ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
                script_text = script_data.get('script', '')
                topic = script_data.get('topic', 'í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤')
                background_images = self.download_background_images(topic, count=5, script_text=script_text)
            else:
                # AI ì´ë¯¸ì§€ ì‚¬ìš© (ì„¹ì…˜ ìˆœì„œë¡œ ì •ë ¬)
                section_order = ["intro", "section1", "section2", "section3", "outro"]
                background_images = []
                for section in section_order:
                    for sec, img in ai_images:
                        if sec == section:
                            background_images.append(img)
                            break
            
            # ì„¹ì…˜ ê²½ê³„ ê°ì§€ (ì´ë¯¸ì§€ íƒ€ì´ë° ë™ê¸°í™”)
            section_times = self._detect_section_boundaries(sentence_timings, duration) if sentence_timings else None
            
            # ë°°ê²½ ë¹„ë””ì˜¤ ìƒì„± (ì„¹ì…˜ íƒ€ì´ë° ì ìš©)
            background = self.create_background_video(background_images, duration, section_times=section_times)
            
            # ìë§‰ ìƒì„± (ìŒì„± íƒ€ì´ë° ê¸°ë°˜)
            subtitle_clips = self.create_subtitle_clips(script_data['script'], duration, sentence_timings=sentence_timings)
            
            # ì¸ë„¤ì¼ ìƒì„±: ì¸íŠ¸ë¡œ ë°°ê²½ + í›„í‚¹ ë¬¸ì¥ (Nê°€ì§€) ì˜¤ë²„ë ˆì´
            if sentence_timings and background_images:
                import re
                hook_text = None
                for timing in sentence_timings:
                    if re.search(r'\d+ê°€ì§€', timing['text']):
                        hook_text = timing['text']
                        break
                if hook_text and len(background_images) > 0:
                    thumb_path = output_path.replace('.mp4', '_thumb.jpg')
                    os.makedirs(os.path.dirname(thumb_path), exist_ok=True)
                    self._thumbnail_path = self._create_hook_thumbnail(
                        background_images[0], hook_text, thumb_path
                    )
            
            # ëª¨ë“  í´ë¦½ í•©ì„±
            final_video = CompositeVideoClip(
                [background] + subtitle_clips,
                size=(self.width, self.height)
            ).with_duration(duration).with_audio(audio)
            
            # ë¹„ë””ì˜¤ ì €ì¥ (MoviePy ì¶œë ¥ì„ ìº¡ì²˜í•˜ì—¬ í•œ ì¤„ë¡œ í‘œì‹œ)
            captured_output = io.StringIO()
            
            with redirect_stdout(captured_output):
                final_video.write_videofile(
                    output_path,
                    fps=self.fps,
                    codec='libx264',
                    audio_codec='aac',
                    temp_audiofile='temp-audio.m4a',
                    remove_temp=True,
                    preset='medium'
                )
            
            # ìº¡ì²˜ëœ ì¶œë ¥ì—ì„œ progress bar ë¼ì¸ë“¤ë§Œ ì¶”ì¶œ
            output_lines = captured_output.getvalue().split('\n')
            last_progress_line = ""
            
            for line in output_lines:
                # frame_indexë‚˜ chunkë¥¼ í¬í•¨í•œ ì§„í–‰ ë¼ì¸ ì°¾ê¸°
                if 'frame_index' in line or 'chunk' in line or '|' in line:
                    # í•œ ì¤„ì— ë®ì–´ì”Œìš°ê¸°
                    sys.stdout.write(f'\r{line}')
                    sys.stdout.flush()
                    last_progress_line = line
                elif line.strip() and 'MoviePy' in line:
                    # ì™„ë£Œ ë©”ì‹œì§€ëŠ” ìƒˆ ì¤„ë¡œ ì¶œë ¥
                    print(f"\n{line}")
            
            # ë§ˆì§€ë§‰ì— ìƒˆ ì¤„ ì¶”ê°€
            if last_progress_line:
                print()
            
            print(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if final_video:
                try:
                    final_video.close()
                except Exception:
                    pass
            if audio:
                try:
                    audio.close()
                except Exception:
                    pass


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    generator = VideoGenerator()
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
    test_script = {
        'script': 'ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ì˜ìƒì…ë‹ˆë‹¤. ìë§‰ì´ ì˜ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.',
        'thumbnail_text': 'í…ŒìŠ¤íŠ¸ ì˜ìƒ'
    }
    
    print("ë¹„ë””ì˜¤ ìƒì„±ê¸°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
