#!/usr/bin/env python3
"""ìë§‰ ìŠ¤íƒ€ì¼ + ë¬´ë£Œ AI ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
import os
import sys
import time
import requests
from PIL import Image

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
os.makedirs("output/longform_images", exist_ok=True)
os.makedirs("output/longform_videos", exist_ok=True)

print("=" * 60)
print("ğŸ§ª ìë§‰ ìŠ¤íƒ€ì¼ + AI ì¼ëŸ¬ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸")
print("=" * 60)

# â”€â”€ í…ŒìŠ¤íŠ¸ 1: ìë§‰ ë°°ê²½ë°•ìŠ¤ (í…ìŠ¤íŠ¸ ë§ì¶¤ ë„ˆë¹„ + ì¶©ë¶„í•œ ë†’ì´) â”€â”€
print("\nğŸ”¹ í…ŒìŠ¤íŠ¸ 1: ìë§‰ ë°°ê²½ë°•ìŠ¤ ìŠ¤íƒ€ì¼")
try:
    from moviepy import TextClip, ImageClip, CompositeVideoClip

    font_path = "/System/Library/Fonts/AppleSDGothicNeo.ttc"

    test_subs = [
        (0, 3, "ì§§ì€ ìë§‰"),
        (3, 7, "ì¤‘ê°„ ê¸¸ì´ì˜ ìë§‰ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"),
        (7, 10, "ê¸´ ë¬¸ì¥ì˜ ìë§‰ì…ë‹ˆë‹¤ ì´ë ‡ê²Œ ë˜ë©´\në‘ ì¤„ë¡œ ë‚˜ë‰˜ì–´ì•¼ í•©ë‹ˆë‹¤"),
    ]

    bg_path = "output/longform_images/test_pexels_0.jpg"
    if os.path.exists(bg_path):
        bg_clip = ImageClip(bg_path).with_duration(10)
    else:
        from moviepy import ColorClip
        bg_clip = ColorClip(size=(1920, 1080), color=(20, 30, 60)).with_duration(10)

    text_clips = []
    for start, end, text in test_subs:
        kw = {
            "text": text,
            "font_size": 48,
            "color": "white",
            "bg_color": "black",
            "method": "label",
            "margin": (30, 15),
            "transparent": False,
            "duration": end - start,
        }
        if font_path and os.path.exists(font_path):
            kw["font"] = font_path

        tc = TextClip(**kw)
        print(f"  ìë§‰: '{text[:20]}...' â†’ í¬ê¸°: {tc.size}")
        tc = tc.with_start(start).with_position(("center", 900))
        text_clips.append(tc)

    composite = CompositeVideoClip([bg_clip] + text_clips, size=(1920, 1080)).with_duration(10)
    preview_path = "output/longform_videos/preview_subtitle_test.mp4"
    t0 = time.time()
    composite.write_videofile(preview_path, fps=30, codec="libx264", audio_codec="aac")
    elapsed = time.time() - t0
    composite.close()
    fsize = os.path.getsize(preview_path) / 1024
    print(f"  âœ… ë¯¸ë¦¬ë³´ê¸°: {preview_path} ({fsize:.0f}KB, {elapsed:.1f}ì´ˆ)")
except Exception as e:
    print(f"  âŒ ìë§‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()


# â”€â”€ í…ŒìŠ¤íŠ¸ 2: ë¬´ë£Œ AI ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„± API ì‹œë„ â”€â”€
print("\n" + "=" * 60)
print("ğŸ”¹ í…ŒìŠ¤íŠ¸ 2: ë¬´ë£Œ AI ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„± API")
print("=" * 60)

# 2-1. Pollinations AI
print("\n[1] Pollinations AI (flux-realism)")
try:
    prompt = "peaceful mountain landscape, soft illustration style, pastel colors, no text, digital art"
    url = f"https://image.pollinations.ai/prompt/{requests.utils.quote(prompt)}?width=1920&height=1080&nologo=true&model=flux-realism"
    resp = requests.get(url, timeout=60, allow_redirects=True)
    ct = resp.headers.get("content-type", "")
    if resp.status_code == 200 and "image" in ct:
        path = "output/longform_images/test_pollinations.jpg"
        with open(path, "wb") as f:
            f.write(resp.content)
        img = Image.open(path)
        print(f"    âœ… ì„±ê³µ: {img.size}, íŒŒì¼: {path}")
    else:
        print(f"    âŒ ì‹¤íŒ¨: status={resp.status_code}, ct={ct}")
except Exception as e:
    print(f"    âŒ ì—ëŸ¬: {e}")

# 2-2. Hugging Face Inference API (ë¬´ë£Œ, ì¸ì¦ ë¶ˆí•„ìš”)
print("\n[2] Hugging Face Inference API (stabilityai/stable-diffusion-xl-base-1.0)")
try:
    hf_url = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
    payload = {"inputs": "soft illustration of a peaceful sunrise over mountains, pastel colors, digital art style, no text, calming mood"}
    resp = requests.post(hf_url, json=payload, timeout=60)
    ct = resp.headers.get("content-type", "")
    print(f"    ìƒíƒœ: {resp.status_code}, ct: {ct}")
    if resp.status_code == 200 and "image" in ct:
        path = "output/longform_images/test_hf_sdxl.png"
        with open(path, "wb") as f:
            f.write(resp.content)
        img = Image.open(path)
        print(f"    âœ… ì„±ê³µ: {img.size}, íŒŒì¼: {path}")
    elif resp.status_code == 503:
        print(f"    â³ ëª¨ë¸ ë¡œë”© ì¤‘ (ì½œë“œ ìŠ¤íƒ€íŠ¸). ì¬ì‹œë„ í•„ìš”.")
        body = resp.json() if resp.headers.get("content-type","").startswith("application/json") else {}
        est = body.get("estimated_time", "?")
        print(f"    ì˜ˆìƒ ëŒ€ê¸°: {est}ì´ˆ")
    else:
        print(f"    âŒ body: {resp.text[:200]}")
except Exception as e:
    print(f"    âŒ ì—ëŸ¬: {e}")

# 2-3. Hugging Face - FLUX.1-dev (ë¬´ë£Œ)
print("\n[3] Hugging Face - FLUX.1-schnell (ë¹ ë¥¸ ë¬´ë£Œ ëª¨ë¸)")
try:
    hf_url = "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell"
    payload = {"inputs": "warm illustration of two friends walking in autumn park, soft watercolor style, peaceful mood, no text"}
    resp = requests.post(hf_url, json=payload, timeout=60)
    ct = resp.headers.get("content-type", "")
    print(f"    ìƒíƒœ: {resp.status_code}, ct: {ct}")
    if resp.status_code == 200 and "image" in ct:
        path = "output/longform_images/test_hf_flux.png"
        with open(path, "wb") as f:
            f.write(resp.content)
        img = Image.open(path)
        print(f"    âœ… ì„±ê³µ: {img.size}, íŒŒì¼: {path}")
    elif resp.status_code == 503:
        body = resp.json() if "json" in ct else {}
        est = body.get("estimated_time", "?")
        print(f"    â³ ëª¨ë¸ ë¡œë”© ì¤‘. ì˜ˆìƒ: {est}ì´ˆ")
    else:
        print(f"    body: {resp.text[:200]}")
except Exception as e:
    print(f"    âŒ ì—ëŸ¬: {e}")

# 2-4. Together AI ë¬´ë£Œ ì²´í—˜
print("\n[4] Together AI (FLUX-schnell)")
print("    â†’ ê°€ì… í•„ìš”: https://api.together.xyz")
print("    â†’ ë¬´ë£Œ $1 í¬ë ˆë”§ ì œê³µ (ì•½ 100ì¥ ìƒì„± ê°€ëŠ¥)")

# 2-5. Segmind API
print("\n[5] Segmind API (SDXL)")
print("    â†’ ê°€ì… ì‹œ 100 í¬ë ˆë”§ ë¬´ë£Œ: https://www.segmind.com")

print("\n" + "=" * 60)
print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print("=" * 60)
